\section{Differential Approximation of the Terminal Cost}
\label{sec:methods}
%
We now introduce the quadratic approximation scheme of the value function.
 We seek a pair of \emph{saddle point equilibrium} policies, $(\control^*, \disturb^*)$ that satisfy the following inequalities for a cost $\valuefunc$ at an initial time $T$,
\[
\valuefunc(T; \state(T), \control^*, \disturb) \leq \valuefunc(T; \state(T), \control^*, \disturb^*) \leq \valuefunc(T; \state(T), \control, \disturb^*),
\]
$ \forall \, \control \in \mc{U}, \disturb \in \mc{V}$ and $\state(T)$.
%

The successive approximation to $\valuefunc$ consists in  maintaining local approximations to the global system dynamics at every iteration so that the local state and controls are $\state_r, \control_r, \disturb_r$. We proceed as follows:
%
\begin{itemize}
	\item Approximate the nonlinear system dynamics (c.f. \eqref{eq:sys_dyn}), starting with the pursuer's local controls schedule, $\{ \bar \control(t)\}$, and evader's local controls $\{ \bar \disturb(t) \}$, assumed to be available (when these are not available, we can initialize them to $0$);
	%
	\item  we then run the system's passive dynamics with $\{\bar{\control}\}, \{\bar {\dist} \}$ to generate  a nominal state trajectory $ \{\bar{\state}_t\}$, with neighboring trajectories $\{ \state_t \}$; %deterministic dynamics,
	%
	\item we choose a small neighborhood, $\{\delstate_t\}$ of $\{\state_t\}$, which provides an optimal reduction in cost as the dynamics no longer represent those of $\{\state_t\}$;
	%
	\item  discretizing time, the new state and control sequence pairs become $\delta \state_\tidx = \state_\tidx - \bar \state_\tidx, \,
	\delta \control_\tidx = \control_\tidx - \bar \control_\tidx, \,
	\delta \distbo_\tidx = \distbo_\tidx - \bar \distbo_\tidx$.
	%
\end{itemize}
%
Setting $V(\state, T) = \augreward_{T}(\state_{T})$, the min-max over the entire control sequence reduces to a stepwise optimization over a single control, going backward in time with %the \textit{stage cost}
\begin{align}
	V(\state_\tidx) = \min_{\control_\tidx \sim \pi} \max_{\distbo_\tidx \sim \psi} [\augreward(\state_\tidx, \control_\tidx, \distbo_\tidx) + V(f(\state_{\tidx+1}, \control_{\tidx+1}, \distbo_{\tidx+1}))]. \nonumber
\end{align}


Suppose an (optimal) reduced basis with order $r$ has been found that admits the most energetic modes of $\valuefunc$. Call the cost on this basis $\valuefunc_r$. Define the state, control, and disturbance on the reduced basis as $\state_r(t), \, \control_r(t), \, \text{ and } \disturb_r(t)$ respectively, where $t \in \left[T, 0\right]$. When we decompose the system into the reduced  $\state_r(t), \, \control_r(t), \, \text{ and } \disturb_r(t)$, the dynamics no longer describes the original states and controls, but rather the variation of the state and controls on the reduced basis from the state and the control pairs on the nonlinear system of equation \eqref{eq:sys_dyn} \ie $\delta \state(t), \, \delta \control(t), \,\text{ and } \delta \disturb(t)$ respectively\footnote{Note that $\delta \state(t), \, \delta \control(t), \,\text{ and } \delta \disturb(t)$ are respectively measured with respect to $\state(t), \control(t), \disturb(t)$ and are not necessarily small. However, our case is very much helped when they are small and we conjecture that our decomposition scheme favors the smallness in the values of these variations.}. It follows that we can write the following relations
%
\begin{subequations}
	\begin{align}
		\state(t) &= \state_r(t) + \delta\state(t), \,\, 	\control(t) = \control_r(t) + \delta\control(t), \\
		%
		\disturb(t) &= \disturb_r(t) + \delta\disturb(t), \,\, t \in \left[-T, 0\right].
	\end{align}
	\label{eq:variations}
\end{subequations}
%
For convenience' sake, let us drop the templated time arguments in \eqref{eq:variations} so that our canonical problem becomes
%
\begin{subequations}
	\begin{align}
		\eqref{eq:sys_dyn} \implies \dfrac{d}{dt}\left(\state_r + \delta \state\right) &= f(t; \state_r + \delta \state, \control_r + \delta \control, \disturb_r + \delta \disturb), \,  \\
		& \state_r(0) + \delta \state(0) = \state(0).
	\end{align}
\end{subequations}
%
\eqref{eq:lower_visc} implies 
%
\begin{align}
	\begin{split}
		-\frac{\partial \valuefunc}{\partial t}(\state_r + \delta \state, t)
		&= 
		\min \left\{0,  
		\max_{\delta \control \in \mathcal{U}} \, \min_{\delta \disturb \in \mathcal{V}} \left\langle f(t; \state_r + \delta \state, \right. \right. \\
		&  \left. \left.  \control_r + \delta \control, \disturb_r + \delta \disturb), \dfrac{\partial \valuefunc}{\partial \state}\left(\state_r + \delta \state, t \right) \right\rangle \right\}. 
	\end{split} \nonumber \\
	%
	\eqref{eq:lower_visc_boundary} \implies	\valuefunc(\state_r, 0) &= g(0; \state_r(0) + \delta \state (0));
	\label{eq:canonical_value}
\end{align}
%
and
%
\begin{align}
	\eqref{eq:HJ_traj} \implies	\bm{\xi}(t) = \bm{\xi}(t; t_0, \state_r + \delta\state, 	\control+\delta\control,\disturb+\delta\disturb).
\end{align}
%
In particular, on the reduced order basis (ROB), the state dynamics now become
%
\begin{subequations}
	\begin{align}
		\dot{\state}_r(\tau) &= f(t; \state_r(\tau), \control_r(\tau), \disturb_r(\tau)), \quad \tau \in \left[-T, 0\right] \\
		\state_r(0) &= \state.
	\end{align}
\end{subequations}
%
Let the optimal cost  for using the optimal control $\control^\star(\tau) = \control_r(\tau) + \delta \control^\star(\tau)$ when $\tau \in \left[t, 0\right]$ on the phase $(\state_r, t)$ be denoted $\valuefunc^\star(\state_r, t)$; and the ROM cost for using $\control_r(\tau); \,\, \tau \in \left[t, 0\right]$ be $\valuefunc_r(\state_r, t)$. Suppose further that we denote  the difference between these two costs on the phase $\left(\state_r, t\right)$ by $\costdiff^\star$, then we have
%
\begin{align}
	\costdiff^\star =\valuefunc^\star(\state_r, t) -\valuefunc_r(\state_r, t).
	\label{eq:cost_diff}
\end{align}
%
\begin{theorem}
	The HJI variational inequality \cf \eqref{eq:lower_hji_pde} admits the following approximated expansion on the reduced model:
	\begin{align}
		\begin{split} 
			-\frac{\partial \valuefunc_r}{\partial t} -\frac{\partial \costdiff}{\partial t} - \left\langle \dfrac{\partial\valuefunc_{\state}}{\partial t}, \delta\state \right \rangle -  \dfrac{1}{2} \left\langle \delta \state, \dfrac{\partial \valuefunc_{\state\state} }{\partial t}\delta\state \right \rangle &=  \\
			\min \left\{\bm{0},  
			\max_{\delta \control \in \mathcal{U}} \, \min_{\delta \disturb \in \mathcal{V}} \left\langle f^T(t; \state_r + \delta \state, \control_r + \delta \control,  \disturb_r + \delta \disturb), \right. \right. \\
			\left. \left. \valuefunc_{\state} +  \valuefunc_{\state\state}\, \delta \state \right\rangle \right\}. 
		\end{split}
		\label{eq:ROM_HJI}
	\end{align}
	Furthermore, this expansion is bounded by $O(\delta \state^3)$.
	\label{th:quad_approx}
\end{theorem}
%
\begin{corollary}
	If the viscosity solution obtained via a Lax-Friedrichs integration scheme for solving \eqref{eq:ROM_HJI} converges to a local optimum, then the backward reachable tube will converge to a locally optimal solution. In addition, if we overapproximate the resulting numerical solution, the reachable set or tube will converge to an optimal region in the state space.
\end{corollary}

\begin{proof}
	The  singular value decomposition of $\valuefunc$ is 
	%
	\begin{align}
		\valuefunc = \bm{\Upsilon} \bm{\Lambda} \bm{\Uptheta}^T,
	\end{align}
	%
	where, $\bm{\Upsilon} \in \mathds{C}^{n\times r}, \, \bm{\Lambda} \in \mathds{C}^{r\times r}, \, \bm{\Uptheta} \in \mathds{C}^{m\times r}$,
	and $r\le m$ can be an approximate or exact rank of $\valuefunc$. The modes of the reduced basis are the columns of $\bm{\Upsilon}$ which are ideally orthonormal  \ie $\bm{\Upsilon}^\star\, \bm{\Upsilon} = \mathbf{\identity}$. We are concerned with the leading eigen values and eigenvectors of $\valuefunc$; therefore, we project $\valuefunc$ onto the proper orthogonal decomposition (POD) modes in $\bm{\Upsilon}$ according to 
	%
	\begin{align}
		\valuefunc_r = \bm{\Upsilon}^T \valuefunc \bm{\Upsilon}.
	\end{align}
	%
	This reduced model is the Galerkin projection onto the semidiscrete ordinary differential equations (o.d.e.):
	%
	\begin{align}
		\dfrac{d \valuefunc_r}{dt} = \bm{\Upsilon}^T \dfrac{d \valuefunc}{dt} \bm{\Upsilon}.
	\end{align}
	
	For the moment, let us focus on the l.h.s. of \eqref{eq:canonical_value}. Our derivations  closely follow that of Jacobson~\cite{Jacobson1968new}. The major difference is that our choice of $\state_r$ is guaranteed to be close to that of $\state$ so that we need not prescribe stringent conditions for when local control laws are valid on the nonlinear system.  Suppose the optimal terminal cost, $\valuefunc^\star$, is sufficiently smooth to allow a power series expansion in the state variation $\delta \state$ about reduced state, $\state_r$, we find that 
	%
	\begin{align}
		\valuefunc^\star(\state_r + \delta \state, t) &= \valuefunc^\star(\state_r, t) + \left\langle\valuefunc_{\state}, \delta \state \right\rangle + \dfrac{1}{2} \left\langle \delta \state, \valuefunc^\star_{\state\state} \delta\state \right\rangle \nonumber \\
		& \qquad\qquad\qquad  + \text{h.o.t}.
		\label{eq:volterra_expand}
	\end{align}
	%
	Here, h.o.t. signifies higher order terms. This expansion scheme is consistent with  Volterra-series model order reduction methods~\cite{QLMOR} or differential dynamic programming schemes that  decompose nonlinear systems as a summation of Taylor series expansions~\cite{JacobsonMayne}.  Using \eqref{eq:cost_diff},  \eqref{eq:volterra_expand} becomes
	%
	\begin{align}
		\valuefunc^\star(\state_r + \delta \state, t) &= \valuefunc_r(\state_r, t) + \costdiff^\star + \left\langle\valuefunc_{\state}, \delta \state \right\rangle + \nonumber \\
		& \qquad \dfrac{1}{2} \left\langle \delta \state, \valuefunc^\star_{\state\state} \delta\state \right\rangle + \text{h.o.t}.
		\label{eq:Value_expand}
	\end{align}
	%
	The expansion in \eqref{eq:Value_expand} may be more costly than solving for the original value function owing to the large dimensionality of the states as higher order terms are expanded. However, consider:
	%
	\begin{itemize}
		\item $\valuefunc_r(\state_r, t)$ already contains the dominant modes of $\valuefunc(\state, t)$ as a result of the singular value decomposition scheme; therefore w.l.o.g. states in the reduced order basis (ROB), $\valuefunc_r(\state_r, t)$, will be sufficiently close to those that originate in \eqref{eq:sys_dyn};
		%
		\item If the above is true, the state variation  $\delta \state$ will be sufficiently small owing to the fact that $\state \approx \state_r$  \cf \eqref{eq:variations}.
		%
	\end{itemize}
	%
	Therefore, we can avoid the infinite data storage requirement by truncating the expansion in \eqref{eq:Value_expand} at, say, the quadratic (second-order) terms in $\delta \state$. Seeing that $\delta \state$ is sufficiently small, the second-order cost terms will dominate higher order terms, and this new cost will result in an $O(\delta \state^3)$ approximation error, affording us realizable control laws that can be executed on the system \eqref{eq:sys_dyn}. From \eqref{eq:volterra_expand}, we have
	%
	\begin{align}
		\valuefunc^\star(\state_r + \delta \state, t) &= \valuefunc_r + \costdiff^\star + \left\langle\valuefunc_{\state}, \delta \state \right\rangle +  \dfrac{1}{2} \left\langle \delta \state, \valuefunc^\star_{\state\state} \delta\state \right\rangle.
		\label{eq:val_rom_expand}
	\end{align}
	%
	Denoting by $\valuefunc_{\state}^\star$ the co-state on the r.h.s of \eqref{eq:canonical_value}, we  can similarly expand it up to second order terms as follows
	%
	\begin{align}
		\valuefunc_{\state}^\star\left(\state_r + \delta \state, t \right) = \dfrac{\partial \valuefunc^\star_r}{\partial \state}\left(\state_r , t \right) + \langle \valuefunc^\star_{\state\state}\left(\state_r , t \right), \delta \state \rangle.
		\label{eq:co_state_expand}
	\end{align}
	%
	Note that \textit{the co-state in \eqref{eq:co_state_expand} and parameters on the r.h.s. of \eqref{eq:val_rom_expand} are evaluated on the reduced model, specifically at the phase $\left(\state_r, t\right)$}. Substituting \eqref{eq:val_rom_expand} and \eqref{eq:co_state_expand} into \eqref{eq:canonical_value}, abusing notation by dropping the superscripts and the templated phase arguments, we find that
	%
	\begin{align}
		\begin{split} 
			-\frac{\partial \valuefunc_r}{\partial t} -\frac{\partial \costdiff}{\partial t} - \left\langle \dfrac{\partial\valuefunc_{\state}}{\partial t}, \delta\state \right \rangle -  \dfrac{1}{2} \left\langle \delta \state, \dfrac{\partial \valuefunc_{\state\state} }{\partial t}\delta\state \right \rangle &=  \\
			\min \left\{0,  
			\max_{\delta \control} \, \min_{\delta \disturb} \left\langle f^T(t; \state_r + \delta \state, \control_r + \delta \control,  \disturb_r + \delta \disturb), \right. \right. \\
			\left. \left. \valuefunc_{\state} +  \valuefunc_{\state\state}\, \delta \state \right\rangle \right\}. 
		\end{split}
		\label{eq:ROM_HJI_Proof}
	\end{align}
	%
	%\textit{A fortiori}, we have the optimal Galerkin approximation of the HJI variational problem   \cf \eqref{eq:lower_hji_pde} with the ROM \eqref{eq:ROM_HJI_Proof}. 	
	Observe that $\valuefunc_r+ \costdiff$, $\valuefunc_{\state}$, and $\valuefunc_{\state\state}$ are all functions of the phase $\left(\state, r\right)$ so that 
	\begin{subequations}
		\begin{align}
			\frac{d}{dt}\left(\valuefunc_r + \costdiff\right) &= \dfrac{\partial}{\partial t}\left(\valuefunc_r + \costdiff\right) + \left\langle f^T(t; \state_r, \control_r, \disturb_r), \valuefunc_{\state} \right \rangle \\
			%
			\dot{\valuefunc}_{\state} &= \dfrac{\partial \valuefunc_{\state\state}}{\partial t} + \langle f^T(t; \state_r, \control_r, \disturb_r),  \valuefunc_{\state\state} \rangle \\
			%
			\dot{\valuefunc}_{\state\state} &= \dfrac{\partial \valuefunc_{\state\state}}{\partial t}. %+ \langle f^T(t; \state_r, \control_r, \disturb_r), \valuefunc_{\state\state} \rangle
		\end{align}
		\label{eq:reduced_canonical}
	\end{subequations}
\end{proof} 
%
The left hand side of \eqref{eq:ROM_HJI_Proof} admits a quadratic form, so that we can regress a quadratic form to fit the functionals and derivatives of the optimal structure of the ROB. The r.h.s. can be similarly expanded as above.   Define 
%
\begin{align}
	\hamfunc(t; \state, \control, \disturb, \valuefunc_{\state}) = \langle \valuefunc_{\state}, f(t; \state, \control, \disturb) \rangle 
\end{align}
%
so that \eqref{eq:ROM_HJI_Proof} becomes
%
\begin{align}
	\begin{split} 
		-\frac{\partial \valuefunc_r}{\partial t} -\frac{\partial \costdiff}{\partial t} - \left\langle \dfrac{\partial\valuefunc_{\state}}{\partial t}, \delta\state \right \rangle -  \dfrac{1}{2} \left\langle \delta \state, \dfrac{\partial \valuefunc_{\state\state} }{\partial t}\delta\state \right \rangle &=  \\
		\min \left\{\bm{0},  
		\max_{\delta \control} \, \min_{\delta \disturb} \left[\hamfunc(t; \state_r + \delta \state, \control_r + \delta \control, \disturb + \delta \disturb, \valuefunc_{\state}) + \right. \right. \\
		\left. \left.  \left\langle \valuefunc_{\state\state}\, \delta \state, f(t; \state_r + \delta \state, \control_r + \delta \control,  \disturb_r + \delta \disturb)  \right\rangle\right] \right\}. 
	\end{split}
\label{eq:rob_expand}
\end{align}

Expanding the r.h.s. about $\state_r, \control_r, \disturb_r$ up to second-order only\footnote{This is because the \lhs was truncated at  second order expansion previously. Ultimately, the $\delta \control, \delta \disturb$ terms will be quadratic in $\delta \state$ if we neglect h.o.t.}, we find that
%
\begin{align}
	\begin{split} 
		\min \left\{\bm{0},  
		\max_{\delta \control} \, \min_{\delta \disturb} \left[\hamfunc + \left\langle \hamfunc_{\state}  + \valuefunc_{\state \state} f, \delta \state\right\rangle + \right. \right. \\
		\left. \left. \langle \hamfunc_{\control }, \delta \control \rangle + \langle \hamfunc_{\disturb }, \delta \disturb \rangle +  \langle \delta \control, (\hamfunc_{\control  \state} + f_{\control}^T \valuefunc_{\state \state}) \delta \state  \rangle \right. \right. \\
		\left. \left. 
		%
		+  \left\langle \delta \disturb, (\hamfunc_{\disturb  \state} + f_{\disturb}^T \valuefunc_{\state \state}) \delta \state  \right\rangle + \dfrac{1}{2}\left\langle\delta \control, \hamfunc_{\control  \disturb} \delta \disturb  \right\rangle  \right. \right. \\
		\left. \left. 
		%
		 + \dfrac{1}{2}\left\langle\delta \disturb, \hamfunc_{\disturb  \control} \delta \control \right\rangle +  \dfrac{1}{2} \left\langle \delta \control, \hamfunc_{\control  \control} \delta \control \right\rangle +  \dfrac{1}{2} \left\langle \delta \disturb, \hamfunc_{\disturb  \disturb} \delta \disturb \right\rangle \right. \right. \\
		\left. \left. 
		%
		+    \dfrac{1}{2} \left\langle \delta \state, \left(\hamfunc_{\state \state} + f_{\state}^T \valuefunc_{\state \state}  + \valuefunc_{\state \state} f_{\state} \right) \delta \state \right\rangle \right] \right\}. 
	\end{split}
\label{eq:rob_rhs}
\end{align}
%Suppose that the extrema controls are $\control^\star = \control_r + \delta \control^\star   

Let us recall that %the policy pair $\{\control(t), \disturb(t)\}$ constitute a saddle-point solution  to the differential game %\eqref{eq:sys_dyn}, \eqref{eq:payoff}, 
%with final time $t_f = \inf \{t \in \bb{R}^+: (\state(t), t) \in \mathcal{L}_0\}$ if 
%%
%\begin{align}
%	J(\control^\star(t), \disturb(t)) \le J(\control^\star(t), \disturb^\star(t)) \le J(\control(t), \disturb^\star(t)).
%	\label{eq:saddle_points}
%\end{align}
%
when capture\footnote{A capture occurs when $\evader$'s separation from $\pursuer$ becomes less than a specified \eg capture radius.} occurs, we must have the Hamiltonian of the value function be zero as a necessary condition for the players' saddle-point controls~\cite{Merz1972,Isaacs1965} \ie
%
%\begin{align}
%	\hamfunc_u(t; \state, \bm{u}^\star, \disturb, p) =0, \,\hamfunc_v(t; \state, \bm{u}, \disturb^\star, p) =0,
%\end{align} 
%   
%We have that $\control^\star$ maximizes $\valuefunc$ and $\disturb^\star$ minimizes $\valuefunc$ so that the saddle solution's necessary conditions imply              
%
\begin{align}
	\hamfunc_{\control}(t; \state_r, \control_r^\star, \disturb_r, \valuefunc_{\state}) = 0; \,\hamfunc_{\disturb}(t; \state_r, \control_r, \disturb_r^\star, \valuefunc_{\state}) = 0.
	\label{eq:saddle_funcs}
\end{align}                                                                       %
where $\control_r^\star$ and $\disturb_r^\star$ respectively represent the optimal control laws for both players at time $t$.

A state-control relationship of the following form is sought:
%
\begin{align}
\delta \control = \gain_{\control} \delta \state, \quad \delta \disturb = \gain_{\disturb} \delta \state
\label{eq:gains}
\end{align}
%
so that \eqref{eq:rob_rhs} in the context of  \eqref{eq:saddle_funcs}  yields 
%
\begin{subequations}
	\begin{align}
		\hamfunc_{\control} &+ \hamfunc_{\control  \control} \delta \control  + \left(\hamfunc_{\control  \state} + f_{\control}^T \valuefunc_{\state \state}\right) \delta \state + \dfrac{1}{2}\hamfunc_{\control  \disturb} \delta \disturb = 0 \\
		%
		\hamfunc_{\disturb} &+ \hamfunc_{\disturb  \disturb} \delta \disturb  + \left(\hamfunc_{\disturb  \state} + f_{\disturb}^T \valuefunc_{\state \state}\right) \delta \state + \dfrac{1}{2}\hamfunc_{\disturb\control} \delta \control = 0.
	\end{align}
\end{subequations}
%
Using \eqref{eq:saddle_funcs} and equating like terms in the resulting equation to  those in \eqref{eq:gains}, we have the following for the state gains:
%
\begin{align}
	\gain_{\control} &= - \dfrac{1}{2}\hamfunc_{\control  \control}^{-1} \left[ \hamfunc_{\control  \disturb}\gain_{\disturb}  + 2\left(\hamfunc_{\control  \state} + f_{\control}^T \valuefunc_{\state \state}\right) \right], \text{ and} \\
	%
	\gain_{\disturb} &= - \dfrac{1}{2}\hamfunc_{\disturb  \disturb}^{-1} \left[\hamfunc_{\disturb  \control} \gain_{\control} +  2\left(\hamfunc_{\disturb  \state} + f_{\disturb}^T \valuefunc_{\state \state}\right)\right]. \nonumber
\end{align}        

Putting the maximizing $\delta \control$ and the minimizing $\delta \disturb$ into \eqref{eq:rob_rhs}, whilst neglecting terms in $\delta \state$ beyond second-order, we have
%
\begin{align}
	\begin{split} 
		\min \left\{\bm{0},  
		 \left[\hamfunc + \left\langle \left(\hamfunc_{\state}  + \valuefunc_{\state \state} f + \gain_{\control}^T \hamfunc_{\control} + \gain_{\disturb}^T \hamfunc_{\disturb}\right), \delta \state \right\rangle  \right. \right. \\ \left. \left.
		 %
		+    \dfrac{1}{2} \left\langle \delta \state, \left(\hamfunc_{\state \state} + f_{\state}^T \valuefunc_{\state \state}  + \valuefunc_{\state \state} f_{\state}  + \gain_{\control}^T \hamfunc_{\control  \control}  \gain_{\control} 
		 \right.\right. \right. \right.  \\ \left. \left. \left. \left. 
		%
		+ \gain_{\disturb}^T \hamfunc_{\disturb  \disturb}  \gain_{\disturb} \right) \delta \state \right\rangle \right] \right\}. 
	\end{split}
	\label{eq:rob_ham_analytical}
\end{align}
%
Now, we can compare coefficients with the \lhs of \eqref{eq:rob_expand} and find the quadratic expansion of the reduced value function admits the following analytical solution on its right hand side:
%
\begin{subequations}
	\begin{align}
		%\begin{split}
		-\dfrac{\partial \valuefunc_r}{\partial t} - \dfrac{\partial \tilde{\valuefunc}}{\partial t} = \min\{\bm{0}, \hamfunc\} \\
		%
		-\dfrac{\partial \valuefunc_{\state}}{\partial t} = \min \left\{\bm{0}, \hamfunc_{\state} + \valuefunc_{\state\state} \, f + \gain_{\control}^T \hamfunc_{\control } + \gain_{\disturb}^T \hamfunc_{\disturb} \right\} \\
		%
		-  \dfrac{\partial \valuefunc_{\state \state}}{\partial t} = \min \left\{\bm{0}, \hamfunc_{\state \state} + f_{\state}^T\valuefunc_{\state\state} + \valuefunc_{\state\state} f_{\state}  \right. \nonumber \\
		\left.
		+ \gain_{\control}^T \hamfunc_{\control  \control}  \gain_{\control} +  \gain_{\disturb}^T \hamfunc_{\disturb  \disturb}  \gain_{\disturb} \right\}.
		%\end{split}
		%		
	\end{align}
\end{subequations}
%
%
Furthermore, comparing the above with \eqref{eq:reduced_canonical} and noting that $-\dot{\valuefunc}_r = 0$\footnote{The stage cost is zero from \eqref{eq:payoff}.}, we find that 
%
\begin{subequations}
	\begin{align}
		%\begin{split}
		- \dot{ \tilde{\valuefunc}} = - \dfrac{\partial \tilde{\valuefunc}}{\partial t} \triangleq \min\{\bm{0}, \hamfunc - \hamfunc(t; \state_r, \control_r, \disturb_r, \valuefunc_{\state})\} \\
		%
		-\dot{\valuefunc}_{\state} = \min \left\{\bm{0}, \hamfunc_{\state} + \valuefunc_{\state\state} \left(f-f(t; \state_r, \control_r, \disturb_r)\right)  \right. \\
		\left.
		+ \gain_{\control}^T \hamfunc_{\control } + \gain_{\disturb}^T \hamfunc_{\disturb} \right\} \\
		%
		-  \dfrac{\partial \valuefunc_{\state \state}}{\partial t} = \min \left\{\bm{0}, \hamfunc_{\state \state} + f_{\state}^T\valuefunc_{\state\state} + \valuefunc_{\state\state} f_{\state}  \right. \nonumber \\
		\left.
		+ \gain_{\control}^T \hamfunc_{\control  \control}  \gain_{\control} +  \gain_{\disturb}^T \hamfunc_{\disturb  \disturb}  \gain_{\disturb} \right\}
		%\end{split}
		%		
	\end{align}
\end{subequations}
%
where $\gain_{\control}$ and $\gain_{\disturb}$ are as defined in \eqref{eq:gains}. Note that at a saddle point, the first-order necessary condition for optimality \cf \eqref{eq:saddle_funcs} implies  %$\hamfunc_{\control}(t; \state_r, \control^\star, \disturb^\star) = 0$ and $\hamfunc_{\disturb}(t; \state_r, \control^\star, \disturb^\star) = 0$ so that
%
\begin{subequations}
	\begin{align}
		- \dot{ \tilde{\valuefunc}} = \min\{0, \hamfunc - \hamfunc(t; \state_r, \control_r, \disturb_r, \valuefunc_{\state})\} \\
		%
		-\dot{\valuefunc}_{\state} = \min \left\{0, \hamfunc_{\state} + \valuefunc_{\state\state} \left(f-f(\state_r, \control_r, \disturb_r)\right) \right\} \\
		%
		-  \dfrac{\partial \valuefunc_{\state \state}}{\partial t} = \min \left\{\bm{0}, \hamfunc_{\state \state} + f_{\state}^T\valuefunc_{\state\state} + \valuefunc_{\state\state} f_{\state}  \right. \nonumber \\
		\left.
		+ \gain_{\control}^T \hamfunc_{\control  \control}  \gain_{\control} +  \gain_{\disturb}^T \hamfunc_{\disturb  \disturb}  \gain_{\disturb} \right\}
	\end{align}
	\label{eq:saddle_reduce}
\end{subequations}
%
whereupon every quantity in \eqref{eq:saddle_reduce} is evaluated at $\state_r, \control^\star$.

The boundary conditions for \eqref{eq:saddle_reduce} at $t = 0$ is 
%
\begin{align}
	\valuefunc(\state_r, 0) = \valueterm(0; \state_r(0));
\end{align} 
%
so that
%
\begin{subequations}
	\begin{align}
		\tilde{\valuefunc}(0) &= 0 \\
		\valuefunc_{\state}(0) &= \valueterm_{\state} (0; \state_r(0)) \\
		\valuefunc_{\state \state} (0) &= \valueterm_{\state \state} (0; \state_r(0)).
	\end{align}
\end{subequations}

The following control laws are then applied 
%
\begin{align}
	\control &= \control_r +  \gain_{\control} \delta \state, \\
	%
	\disturb &= \disturb_r +  \gain_{\disturb} \delta \state.	
\end{align}

Therefore, at any time on a ROB of the value function, a local approximation of $\valuefunc$ consists in employing the \todo{Lax-Friedrichs scheme} on the following system
%
\begin{align}
	\begin{split}
		-\left[\bm{E} + \bm{F} \delta \state + \dfrac{1}{2} \delta \state \bm{G} \delta \state  \right] = \min \left\{\bm{0}, \hamfunc    \right. \\ \left. % \left.
		- \hamfunc(t; \state_r, \control_r, \disturb_r, \valuefunc_{\state})+ \hamfunc_{\state}+ \valuefunc_{\state\state} \left(f-f(t; \state_r, \control_r, \disturb_r)\right) \right. \\ \left. 
		 + \hamfunc_{\state \state} 
		+ f_{\state}^T\valuefunc_{\state\state} + \valuefunc_{\state\state} f_{\state} 	+ \gain_{\control}^T \hamfunc_{\control  \control}  \gain_{\control} +  \gain_{\disturb}^T \hamfunc_{\disturb  \disturb}  \gain_{\disturb} \right\}
	\end{split}
\end{align}
%
where $ \bm{E}, \bm{F},  \, \text{ and } \,\bm{G}$ are appropriately defined.

\begin{comment}
%
%By definition, backward reachable tubes (BRTs) are the sublevel sets of the viscosity solutions to 
The numerical resolution of hyperbolic\footnote{Hyperbolic PDEs are those that depend on at most the first-order partial derivatives of the vector field under consideration.} HJ PDEs~\cite{Mitchell2020} in a viscosity sense comes from the resolution of scalar continuous conservation laws e.g. the conservation of electric charge density, $\rho$ (in $\text{Coulombs}/m^{2}$), of an electromagnetic field  i.e.,
%
\begin{align}
\dfrac{\partial \rho}{\partial t} +(\nabla \cdot \bm{J}) = 0
\label{eq:conserve}
\end{align}
%
where $\bm{J}$ is the current density (in $Amperes/m^{2}$). If we relax the viscous properties of these conservation laws, they are effectively reduced to compressible inviscid  Euler equations with discontinuities~\cite{LevelSetsBook}. The discontinuities in the Euler dynamics of such inviscid conservation equations make their  resolution extendable to the numerical solution of HJI PDEs. We restate the following culminations from \cite{OsherShuENO} to build the case for our decomposition scheme.
%
\begin{remark}
The solution (\eg $\rho$ from \eqref{eq:conserve}) to a conservation law is tantamount to the derivative of the solution to an HJ PDE \textbf{along a single spatial dimension}.
\end{remark}
%
%
\begin{remark}
The solution of an HJ PDE, e.g. $\bm{u}$ or $\bm{v}$ in \eqref{eq:lower_visc}, \textbf{along a single spatial dimension}, is the integral of the solution of a scalar conservative equation, \eg $\rho$ in \eqref{eq:conserve}.
\label{rem:integral_conserve}
\end{remark}
%
%The above two remarks are conclusions drawn from \cite{OsherShuENO}. 
Remark \autoref{rem:integral_conserve} informs us that HJ solutions obtained by integrating conservation law PDEs that possess discontinuous dynamics may lead to kinks in the HJ solutions\footnote{Since the integral of a discontinuity is a kink.}. For our proposed decomposition of BRS/BRT, if a  decomposed HJ PDE's solution (to be introduced shortly) develops kinks in its solution, a form of bang-bang control needs be considered if indeed the partial derivatives are discontinuous in those regions of the state space. If the conservation law does not develop a delta function, we can discount accounting for these discontinuities as the HJ solution will be continuous.  In the level set methods, to assure a monotone decrement in the value function, Lax-Friedrich schemes with carefully chosen artificial dissipation coefficients are used in computing solutions to the discretized Hamiltonian in order to account for constant or varying spatial dynamics\footnote{Although in the level sets toolbox, dissipation coefficients are chosen with the assumption that the underlying dynamics are spatially constant; this is very limiting for environments with unpredictable dynamics.} and alleviate possible numerical inconsistencies in computed gradients to the HJ PDE\footnote{This is discussed at length in ~\cite[\S5.3.1]{LevelSetsBook}.}.
\end{comment} 

