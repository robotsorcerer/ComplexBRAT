\section{Background and Preliminaries.}
\label{sec:related}

\subsection{Dynamic Programming and Two-Person Games.}

\noindent The formal relationships between the dynamic programming (DP) optimality condition for the \textit{value} in differential two-person zero-sum games, and the solutions to PDEs that solve ``min-max" or ``max-min" type nonlinearity (the Isaacs' equation) was presented in~\cite{Isaacs1965}. Essentially, Isaacs' claim was that if the \textit{value} functions are smooth enough, then they solve certain first-order partial differential equations (PDE) problems with  ``max-min" or ``min-max"-type nonlinearity.  However, the DP value functions are seldom regular enough to admit a solution in the classical sense.  ``Weaker" solutions on the other hand~\cite{Lions1982, Evans1984, Crandall1984, CrandallLaxFriedrichs, Souganidis} provide generalized ``viscosity" solutions to HJ PDEs under relaxed regularity conditions; these viscosity solutions are not necessarily differentiable anywhere in the state space, and the only regularity prerequisite in the definition is continuity~\cite{Crandall1983viscosity}. However, wherever they are differentiable, they satisfy the  upper and lower values of HJ PDEs in a classical sense. Thus, they lend themselves well to many real-world problems existing at the interface of discrete, continuous, and hybrid systems~\cite{LygerosReachability, OsherFronts, Mitchell2020, Souganidis, Mitchell2005}. Matter-of-factly, viscosity Solutions to \textit{Cauchy-type} HJ Equations admit usefulness in backward reachability analysis~\cite{Mitchell2005}. In scope and focus, this is the bulwark upon which we build our formulation in this paper.

%\subsection{System Dynamics.}

For a state $\state \in \openset$ and a fixed time $t$: $0 \le t < T$, suppose that the set of all controls for players $\pursuer$ and $\evader$ are respectively
%
\begin{align}
	\mathcal{\bar{U}} &\equiv \{\bm{u}: [t, T] \rightarrow \mathcal{U} | \bm{u} \text{ measurable}, \, \mathcal{U} \in \bb{R}^m \}, \\
	\mathcal{\bar{V}} &\equiv \{\bm{v}: [t, T] \rightarrow \mathcal{V} | \bm{v} \text{ measurable},  \,\mathcal{V} \subset \reline^p\}.
\end{align}
%
\noindent We are concerned with the  differential equation,
%
\begin{subequations}
	\begin{align}
		\dot{\state}(\tau) &= f(\tau, \state(\tau), \bm{u}(\tau), \bm{v}(\tau)) \quad t \le \tau \le T \\
		\state(t) &= \state,
	\end{align}
	\label{eq:sys_dyn}
\end{subequations}
%
\noindent where $f(\tau, \cdot, \cdot, \cdot)$ and $\state(\cdot)$ are bounded and Lipschitz continuous. This bounded Lipschitz continuity property assures uniqueness of the system response $\state(\cdot)$ to controls $\bm{u}(\cdot)$ and $\bm{v}(\cdot)$~\cite{Souganidis}. %,  and we note that a single player definition is defined in~\cite{LygerosReachability}. 
%
Associated with \eqref{eq:sys_dyn} is the payoff functional %for the problem of Bolza, 
%
\begin{align}
	\bm{P}(\bm{u}, \bm{v}) &=	\bm{P}(t; \state, \bm{u}(\cdot), \bm{v}(\cdot)) \nonumber \\
	&= \int_{t}^{T} l(\tau, \state(\tau), \bm{u}(\tau), \bm{v}(\tau)) d\tau + g(\state(T)),
	\label{eq:payoff}
\end{align}
%
where $g(\cdot): \bb{R}^n \rightarrow \bb{R}$ %is bounded from above and  Lipschitz continuous \ie it 
satisfies
%
\begin{subequations}
	\begin{align}
		| g(\state) | &\le k_1 \\
		| g(\state) - g(\hat{\state}) \mid &\le k_1 | \state - \hat{\state} \mid
	\end{align}
\end{subequations}
%
and $l:[0, T] \times  \reline^n \times \mathcal{U} \times \mc{V} \rightarrow \bb{R}$ is bounded and uniformly continuous, with
%
\begin{subequations}
	\begin{align}
		\mid l(t; \state, \control, \disturb) \mid &\le k_1 \\
		\mid l(t; \state, \control, \disturb)  -  l(t; \hat{\state}, \control, \disturb) \mid & \le k_2 \mid \state - \hat{\state} \mid
	\end{align}
\end{subequations}
%
for constants $k_1, k_2$ and all %In addition, the flow field $l: [0, T] \times \reline^n \times \mathcal{U} \times \mathcal{V} \rightarrow \reline$ is bounded, and uniformly continuous over
 $0 \le t \le T$, $\state \in \reline^n$, $\bm{u}\in \mathcal{U}$ and $\disturb \in \mathcal{V}$. 
The evader's goal is to maximize the payoff \eqref{eq:payoff} and pursuer's goal is to minimize it. %Henceforward, we refer to $\bm{V}$ as the value.


\subsection{Upper and Lower Values of the Differential Game.}

\noindent Suppose that the pursuer's mapping strategy (starting at $t$) is $\beta: \mathcal{\bar{U}}({t}) \rightarrow \mathcal{\bar{V}}({t})$ provided for each $t \le \tau \le T$ and $\bm{u}, \hat{\bm{u}} \in \mathcal{\bar{U}}({t})$; then $\bm{u}(\bar{t}) = \hat{\bm{u}}(\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$ implies $\beta[\bm{u}](\bar{t}) = \beta[\hat{\bm{u}}](\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$.
%
The differential game's lower value for a solution $\state(t)$ that solves \eqref{eq:sys_dyn} for $\bm{u}(t)$ and $\bm{v}(t) = \beta[\control](\cdot)$ is 
%
\begin{align}
	&\lowervalue(\state, t) = \inf_{\beta \in \mathcal{B}(t)} \sup_{\bm{u} \in \mathcal{U}(t)} \bm{P}(\bm{u}, \beta[\bm{u}]) \nonumber \\
	&=  \inf_{\beta \in \mathcal{B}(t)} \sup_{\bm{u} \in \mathcal{U}(t)} %\left\{
	\int_{t}^{T} l(\tau, \bm{x}(\tau), \bm{u}(\tau), \beta[\bm{u}](\tau)) d\tau + g\left(\bm{x}(T)\right). %
	\label{eq:value_lower}
\end{align}

Similarly, suppose that  the evader's mapping strategy (starting at $t$) is $\alpha: \mathcal{\bar{V}}({t}) \rightarrow \mathcal{\bar{U}}({t})$ provided for each $t \le \tau \le T$ and $\bm{v}, \hat{\bm{v}} \in \mathcal{\bar{V}}({t})$; then  $\bm{v}(\bar{t}) = \hat{\bm{v}}(\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$ implies $\alpha[\bm{v}](\bar{t}) = \alpha[\hat{\bm{v}}](\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$. The differential game's upper value for a solution $\bm{x}(t)$ that solves \eqref{eq:sys_dyn} for $\bm{u}(t) = \alpha[\bm{v}](\cdot)$ and $\bm{v}(t)$  is 
%
\begin{align}
	&\uppervalue(\state, t) = \sup_{\alpha \in \mathcal{A}(t)} \inf_{\bm{v} \in \mathcal{V}(t)}  \bm{P}(\alpha[\bm{v}], \bm{v}) \nonumber \\
	&=  \sup_{\alpha \in \mathcal{A}(t)} \inf_{v \in \mathcal{V}(t)} %\left\{
	\int_{t}^{T}l(\tau, \bm{x}(\tau), \alpha[\bm{v}](\tau), \bm{v}(\tau)) d\tau  + g\left(\bm{x}(T)\right).
	\label{eq:value_upper}
\end{align}

These non-local PDEs \ie \eqref{eq:value_lower} and \eqref{eq:value_upper} are hardly smooth throughout the state space so that they  lack classical solutions even for smooth Hamiltonian and boundary conditions. However, these two values are ``viscosity" (generalized)  solutions~\cite{Lions1982, Crandall1983viscosity} of the associated HJ-Isaacs (HJI) PDE, \ie solutions which are \textit{locally Lipschitz} in $\openset \times [0, T]$, and with at most first-order partial derivatives in the Hamiltonian. In what follows, we introduce the notion of viscosity solutions to the HJI payoff/value functionals in \eqref{eq:value_upper}, and \eqref{eq:value_lower}.


\subsection{Viscosity Solution of HJ-Isaac's Equations.}
\label{subsec:visc}

\noindent  We now establish two Lemmas from~\cite{Souganidis} that will aid the construction of our main contribution in this paper. 
%
\begin{lemma}
	The lower value $\lowervalue$ in \eqref{eq:value_lower} is the viscosity solution to the lower Isaac's equation 
	%
	\begin{subequations}
		\begin{align}
			&\frac{\partial \lowervalue}{\partial t} + \lowerham (t; \state, \bm{u}, \bm{v}, \lowervalue_{\state}) = 0, \,\, t\in \left[0, T\right]\, \state \in \ren  \\
			&\lowervalue(\state, T) = g(x(T)), \quad \state \in \reline^m
			\label{eq:lower_visc_boundary}
		\end{align}
		\label{eq:lower_visc}
	\end{subequations}
	%
	with lower Hamiltonian, 
	%
	\begin{align}
		&\lowerham (t; \state, \bm{u}, \bm{v}, p) = \max_{u \in \mathcal{U}} \min_{v \in \mathcal{V}} \, \langle f(t; \state, \bm{u}, \bm{v}), p  \rangle.
		\label{eq:lower_visc_ham}
	\end{align}
%
where $p$, the co-state, is the spatial derivative of $\lowervalue$ w.r.t $\state$.
	\label{lemma:lower_visc_lemma}
\end{lemma}
%
\begin{lemma}
	The upper value $\uppervalue$ in \eqref{eq:value_upper} is the viscosity solution of the upper Isaac's equation 
	%
	\begin{subequations}
		\begin{align}
			&\frac{\partial \uppervalue}{\partial t} + \upperham (t; \state, \bm{u}, \bm{v},  \uppervalue_{\state})= 0, \, t\in \left[0,T\right],\, \state \in \ren
			 \\
			&\uppervalue(\state, T) = g(\state(T)), \quad \state \in \ren
		\end{align}
		\label{eq:upper_visc}
	\end{subequations}
	%
	with upper Hamiltonian, 
	%
	\begin{align}
		\upperham (t; \state, \bm{u}, \bm{v}, p) = \min_{\bm{v} \in \mathcal{V}} \max_{\bm{u} \in \mathcal{U}} \, \langle f(t; \state, \bm{u}, \bm{v}), p \rangle,
	\end{align}
	with $p$ being appropriately defined.
	\label{lemma:upper_visc_lemma}
\end{lemma}
%
\begin{corollary}
	\begin{inparaenum}[(i)]
		\item  $\lowervalue \le \uppervalue \, \text{ over } (t\in \left[0,T\right]\, \state \in \ren)$
		%
		\item if for all $t\in \left[0,T\right], (\state, p) \, \in \ren$,
	\end{inparaenum} 
	%
	the minimax condition is satisfied \ie 	$\upperham(t; \state, \bm{u}, \bm{v}, p) = \lowerham(t; \state, \bm{u}, \bm{v}, p)$, then
	%
	$\lowervalue \equiv \uppervalue$.
\end{corollary}
%
%\begin{proof}
%	These two lemmas are an adaptation of \cite[Th 4.1]{Souganidis}.
%\end{proof}


\subsection{Reachability for Systems Verification.}
\noindent Reachability analysis is one of many verification methods that allows us to reason about (cpntrol-affine) dynamical systems. %For CPS systems, the scalability of existing verification methods is a requirement for the proper verification of complex systems.  
The verification problem may consist in finding a \textit{set of reachable states} that lie along the trajectory of the solution to a first order nonlinear partial differential equation that originates from some initial state $\state_0 = \state(0)$ up to a specified time bound, $t=t_f$. \textit{From a set of initial and unsafe state sets, and a time bound, the time-bounded safety verification problem is to determine if there is an initial state and a time within the bound that the solution to the PDE enters the unsafe set}.

%Reachability for continuous or hybrid systems can be framed within the framework of differential control theory, whose solution can be characterized by variants of Hamilton-Jacobi-Isaacs (HJI) PDEs: \textit{from a set of initial and unsafe state sets, and a time bound, the time-bounded safety verification problem is to determine if there is an initial state and a time within the bound that the solution to the PDE enters the unsafe set}. 
Reachability could be analyzed in a 
%
\begin{itemize}%[(i)]
	\item \textit{forward} sense, whereupon system trajectories are examined to determine if they enter certain states from an \textit{initial set};
	%
	\item \textit{backward} sense, whereupon system trajectories are examined to determine if they enter certain \textit{target sets};
	%
	\item \textit{reach set} sense, in which they are examined to see if states reach a set at a \textit{particular time}; or
	%
	\item \textit{reach tube} sense, in which they are evaluated that they reach a set at a point \textit{during a time interval}.	
\end{itemize} 

Backward reachability consists in avoiding an unsafe set of states under the worst-possible disturbance at all times; relying on nonanticipative control strategies, \cite{Mitchell2005}'s construction does not necessarily use a state feedback control law during games and the worst-possible disturbance assumption is not formally inculcated in the backward reachability analyses used. In a sense, it is reasonable to ignore nonlinear $\mathcal{H}^2$ or $\mathcal{H}^\infty$ analyses for Dubins vehicle~\cite{Dubins1957} dynamics with constant inputs that only vary in sign for either player \cite{Merz1972} since the worst possible disturbance is known ahead of the game. In other problem domains, this is not sufficient, \todo{and in our analyses we provide an $\mathcal{H}^\infty$ scheme~\cite{DoyleBook}'s  in constructing an appropriate \textit{worst-possible} disturbance that  guarantees robustness in continuous control applications}. 

Backward reachable sets (BRS) or tubes (BRTs) are popularly analyzed an a game of two vehicles with non-stochastic dynamics~\cite{Merz1972}. Such BRTs possess discontinuity at cross-over points (which exist at edges) on the surface of the  tube, and may be non-convex. Therefore, treating the end-point constraints under these discontinuity characterizations need careful consideration and analysis when switching control laws if the underlying P.D.E does not have continuous partial  derivatives (we discuss this further in section \ref{sec:methods}). 
 

\subsubsection{Insufficiency of Global Mesh-based Methods}

\noindent  %The prevailing technique in computing the reachable sets \eg in backward reachability methods~\cite{SylviaScalability, Tomlin2000Game, Bansal, Mitchell2020, Chen2021}. These are \textit{non-incremental time-space full grid description of the implicit representation of the DP value function, $V(t, \bm{x})$, over the entire physical space \ie \ie $u(t, \bm{x}) = \sum_i V^i_{t_i} (t) V^i_{\bm{x}_i} (\bm{x})$}. This requires standard mesh-based discretization techniques, where $N$ nodes uniformly discretize each physical space' coordinate. 
%
Consider a reachability problem defined in a space of dimension $D=12$ based on the non-incremental time-space discretization of each space coordinate. For $N=100$ nodes, the total nodes required is $10^{120}$ on the volumetric grid\footnote{Whereas, there are only $10^{97}$ baryons in the observable universe (excluding dark matter)!}. The curse of dimensionality~\cite{Bellman1957} greatly incapacitates current uniform grid discretization methods for guaranteeing the robustness of backward reachable sets (BRS) and tubes (BRTs)~\cite{Mitchell2005} of complex systems. 


Recent works have started exploring scaling up the Cauchy-type HJ problem for guaranteeing safety of higher-dimensional physical systems: the authors of~\cite{Bajcsy} provide local updates to BRS in  unknown static environments with obstacles that may be unknown \textit{a priori} to the agent; using standard meshing techniques for time-space uniform discretization over the entire physical space, and only updating points traversed locally, a safe navigation problem was solved in an   environment assumed to be static. This makes it non-amenable to \textit{a priori} unknown \textit{dynamic} environments where the optimal value to the min-max HJ problem may need to be adaptively updated based on changing dynamics. 

In ~\cite{SylviaScalability}, the grid was naively refined along the temporal dimension, leveraging local decomposition schemes together with warm-starting optimization of the value function from previous solutions in order to accelerate learning for safety under the assumption that the system is either completely decoupled, or coupled over so-called ``self-contained subsystems".  While the empirical results of~\cite{Bansal} demonstrate the feasibility of optimizing for the optimal value function in backward reachability analysis for up to ten dimensions for a system of Dubins vehicles, there are no guarantees that are provided. An analysis exists for a 12 dimensional systems~\cite{KaynamaScalable} with up to a billion data points in the state space, that generates robustly optimal trajectories. However, this is restricted to {linear systems}. Other associated techniques scale reachability with function approximators~\cite{FisacTAC, FisacICRA} in a reinforcement learning framework; again these methods lose the hard safety guarantees owing to the approximation in value function space.  

%Another line of research inquiry explores a universal function approximation of the value function~\cite{Bansal}. Using static data inputs  for deep learning simulations that globally parameterize the value function for a $10D$ system, solutions were empirically validated against an almost analytical robustly controlled backward reachable tube~\cite{Mitchell2020} benchmark. While this is promising, it is not clear that safety and robustness assurances are preserved given the global approximation in  value function space. 

In these sentiments, we seek to answer the following questions for high-dimensional systems: 
%
\begin{itemize}
	\item What role does sparsity play in the representation of BRTs and BRS's for high-order systems?
	%
	\item Can we provide rational decomposition schemes that preserve the  numerical stability of monotone Lax-Friedrichs and essentially non-oscillatory~\cite{OsherShuENO} gradient methods to the HJ values and Hamiltonians?
	%
	\item How scalable are self-contained subsystems partitioning of state spaces~\cite{DecompChenHerbert} to complex systems with possibly high dimensional state spaces?
	%
	\item With projection to reduced order systems, can we relax the strong assumptions made in local decomposition~\cite{FasTrack, DecompChenHerbert} \eg about the dynamics of the global system consisting of separable subsystems?
	%
\end{itemize}
%
We briefly answer the first question. As long as value functions are implicitly defined as signed distance value functions on a grid, there is no possibility of exploiting sparsity for high-dimensional value functions. This is because these value functions are constructed with  signed distance functions with respect to an interface on the grid~\cite[Chapter 2]{LevelSetsBook}. The value function is positive within the interface and negative outside the interface. Therefore, the representation of such values are completely dense. Unless we can find methods to sparsely represent the value function on a grid, exploiting sparsity of the value function is hopeless. In the sections that follow, we seek to answer the other questions posed above.

\subsubsection{Reachability from Differential Games Optimal Control}

\noindent For any admissible control-disturbance pair $(\bm{u}(\cdot), \bm{v}(\cdot))$ and initial phase $(\state_0, t_0)$, Crandall~\cite{Crandall1983viscosity} and Evan's~\cite{Evans1984} claim is that there exists a unique function % $\xi(t)$  
%
\begin{align}
	\bm{\xi}(t) = \bm{\xi}(t; t_0, \state_0, \bm{u}(\cdot), \bm{v}(\cdot))
	\label{eq:HJ_traj}
\end{align}
%
that satisfies \eqref{eq:sys_dyn} a.e. with the property that
\begin{align}
	\bm{\xi}(t_0) = \bm{\xi}(t_0; t_0, \state_0, \bm{u}(\cdot), \bm{v}(\cdot)) = \state_0.
\end{align}
%
Read \eqref{eq:HJ_traj}: the motion of \eqref{eq:sys_dyn} passing through phase $(\bm{x}_0, t_0)$ under the action of control $\bm{u}$, and disturbance $\bm{v}$, and observed at a time $t$ afterwards. One way to design a system verification problem is compute the reachable set of states that lie along the trajectory \eqref{eq:HJ_traj} such that we evade the unsafe sets up to a time \eg $t_f$ within a given time bound \eg $\left[t_0, t_f\right]$. In this regard, we discard the \textit{cost-to-go}, $l(t; \state(\tau), \bm{u}(\tau), \bm{v}(\tau))$ in \eqref{eq:payoff}, \eqref{eq:value_lower}, or \eqref{eq:value_upper} and certify safety as resolving the terminal value, $g(\state(T))$.

In backward reachability analysis, the lower value of the differential game \ie ~\eqref{eq:value_lower} is used in constructing an analysis of the backward reachable set (or tube). Therefore, we can cast a target set as the time-resolved terminal value $\lowervalue(\state, T) = g(\state(T))$ so that given a time bound, and an unsafe set of states, the time-bounded safety verification problem consists in certifying that there is no phase within the target set \eqref{eq:target_set} such that the solution to \eqref{eq:sys_dyn} enters the unsafe set. Following the backward reachability formulation of \cite{Mitchell2005}, we say the zero sublevel set of $g(\cdot)$ in \eqref{eq:lower_visc} \ie
%
\begin{align}
	\mathcal{L}_0 = \{ \state \in \bar{\Omega} \,|\, g(\state) \le 0 \},
	\label{eq:target_set}
\end{align}
%
is the \textit{target set} in the product of space $\mathbb{S}^0 \times \mathbb{R}$ for a backward reachability problem (proof in \cite{Mitchell2005}). This target set can represent the failure set, regions of danger, or obstacles to be avoided etc in the state space. Note that the target set, $\mathcal{L}_0$, is a closed subset of $\ren$ and is in the closure of $\openset$. And the \textit{robustly controlled backward reachable tube} for $\tau \in [T, 0]$\footnote{The (backward) horizon $T$ is negative.} is the closure of the open set
%
\begin{align}
	\mathcal{L}([\tau, 0], \mathcal{L}_0) &= \{\state \in \openset \,| \, \exists \, \beta \in \mathcal{\bar{V}}(t) \,  \forall \, \bm{u} \in \mathcal{U}(t), \exists \, \bar{t} \in [T, 0], \nonumber \\
	& \qquad  \qquad \bm{\xi}(\bar{t})%\left(t; \state_0, t_0, \bm{u}(\cdot), \beta[\bm{u}](\cdot) \right)
	 \in  \mathcal{L}_0 \}, \,\bar{t} \in \left[T, 0\right].
	 \label{eq:rcbrt}
\end{align}
%
Read: the set of states from which the strategies of $\pursuer$, and for all controls of $\evader$ imply that we reach the target set within the interval $[T, 0]$.   More specifically, following Lemma 2 of \cite{Mitchell2005}, the states in the reachable set admit the following properties w.r.t the value function $\valuefunc$
%
\begin{subequations}
	\begin{align}
		\state \in \mathcal{L}_0 &\implies \lowervalue(\state, t) \le 0 \\
		\lowervalue(\state, t) \le 0 &\implies \state \in \mathcal{L}_0.
	\end{align}
\end{subequations}

Observe:
%
\begin{itemize}
	\item The goal of the pursuer, or $\pursuer$, is to drive the system's trajectories into the unsafe set i.e., $\pursuer$ has $\control$ at will and aims to minimize the termination time of the game  (c.f. \eqref{eq:target_set});
	%
	\item The evader, or $\evader$, seeks to avoid the unsafe  set i.e., $\evader$ has controls $\disturb$ at will and seeks to maximize the termination time of the game (c.f.  \eqref{eq:target_set});
	%
	\item $\evader$ has regular controls, $\bm{u}$, drawn from a Lebesgue measurable set, $\mathcal{U}$ (c.f. \eqref{eq:value_lower}).
	%
	\item $\pursuer$ possesses \textit{nonanticipative strategies} (c.f. \eqref{eq:value_lower}) \ie  $\beta[\bm{u}](\cdot)$ such that for any of the ordinary controls, $\bm{u}(\cdot) \in \mathcal{U}$ of $\evader$, $\pursuer$ knows how to optimally respond to $\evader$'s inputs.
\end{itemize}
%
This is a classic reachability problem on the resolution of the infimum-supremum over the \textit{strategies} of $\pursuer$ and \textit{controls} of $\evader$ with the time of capture resolved as an extremum of a cost functional) over a time interval.%~\cite{LygerosReachability}. 
% The order of play is non-consequential because: 
%
%\begin{itemize}		
%	%
%	\item I's \textit{strategy} can instantaneously respond to any choice of II's controller, regardless of I playing first;
%	%
%	%\item If we follow Merz's example~\cite{Merz1972} of putting I at the origin, and it plays first, either player knows what I's response will be to any input of II. 
%	%
%	\item Under I's nonanticipative strategy, the value of the game  is always less than the value under state feedback so that this choice mitigates underapproximation of the state feedback reachable set~\cite{Mitchell2005}.
%\end{itemize}
%
Let us recall that the open-loop policy pair $\{\control(t), \disturb(t)\}$ constitute a saddle-point solution  to the differential game \eqref{eq:sys_dyn}, \eqref{eq:payoff}, with final time $t_f = \inf \{t \in \bb{R}^+: (\state(t), t) \in \mathcal{L}_0\}$ if 
%
\begin{align}
	J(\control^\star(t), \disturb(t)) \le J(\control^\star(t), \disturb^\star(t)) \le J(\control(t), \disturb^\star(t)).
	\label{eq:saddle_points}
\end{align}
%
When capture\footnote{A capture occurs when $\evader$'s separation from $\pursuer$ becomes less than a specified \eg capture radius.} occurs, we must have the Hamiltonian of the value function be zero as a necessary condition for the players' saddle-point controls~\cite{Merz1972,Isaacs1965} \ie,
%
\begin{align}
	\hamfunc_u(t; \state, \bm{u}^\star, \disturb, p) =0, \,\hamfunc_v(t; \state, \bm{u}, \disturb^\star, p) =0,
\end{align} 
where $\control^\star$ and $\disturb^\star$ respectively represent the optimal control laws for both players at time $t$.

\todo{We obtain a \textit{pseudo iterative dynamic game}~\cite{iDG}, albeit in open-loop settings, where either player infers the current state useful enough for generating closed-loop input control laws.} An implicit surface function, $\{\lowervalue{(\state, t)}: \left[-T, 0\right] \times \mathcal{X}\rightarrow\mathbb{R}, \, \forall \, t>0\}$ \ie the terminal value $\lowervalue {(\state, t)}$, that characterizes the target set $\targetset_0$ is the viscosity solution to the HJI PDE
%
\begin{subequations}
	\begin{align}
		\frac{\partial \lowervalue}{\partial t}{(\bm{x}, t)} & + \min \{0, \lowerham (t; \bm{x}, \bm{u}, \bm{v},\lowervalue_{\state}) \} = 0 \\
		\lowervalue(\bm{x},0) &= g(\bm{x}),
	\end{align}
	\label{eq:lower_hji_pde}
\end{subequations}
%
\noindent where the vector field $\lowervalue_{\state}$ is known in terms of the game's terminal conditions so that the overall game is akin to a two-point boundary-value problem. Henceforward, for ease of readability, we will remove the minus superscript on the lower value and Hamiltonian \eqref{eq:lower_visc_ham}. 
% so that we have %
%%
%\begin{subequations}
%	\begin{align}
%		&\frac{\partial \valuefunc}{\partial t} + \min \{0,\hamfunc (t; \state, \bm{u}, \bm{v}, \valuefunc_{\state})\} = 0, \,\, t\in \left[T, 0\right], \, \state \in \ren \\
%		&\valuefunc(\state, 0) = g(x), \quad \state \in \reline^n
%		%\label{eq:lower_visc_boundary}
%	\end{align}
%	%\label{eq:lower_visc}
%\end{subequations}
%%
%with lower Hamiltonian, 
%%
%\begin{align}
%	&\hamfunc (t; \state, \bm{u}, \bm{v}, p) = \max_{u \in \mathcal{U}} \min_{v \in \mathcal{V}} \, \langle f(t; \state, \bm{u}, \bm{v}), p  \rangle.
%	\label{eq:back_ham}
%\end{align}
%%or
%
%\begin{align}
%	\lowerham (t, \state, p) &= \max_{\bm{u} \in \mathcal{U}} \min_{\bm{v} \in \mathcal{V}}  \{ \liederi_f \lowervalue  + h (t, \bm{x}, \bm{u}, \bm{v}) \}.
%\end{align}
%%
%where $\liederi_f \lowervalue$ is the Lie derivative of $\lowervalue(t, \state)$ w.r.t $f(t, \state, \bm{u}, \bm{v})$, so that we can rewrite the above as
%%
%	\begin{align}
%	 \lowervalue_t + \min &\{0, \max_{\bm{u} \in \mathcal{U}} \min_{\bm{v} \in \mathcal{V}}  \{ \liederi_f \lowervalue  + h (t, \bm{x}, \bm{u}, \bm{v}) \}=0 \\
%	\lowervalue(\bm{x},0) &= g(\bm{x}).
%	\label{eq:lower_hji_pde}
%	\end{align}





%\section{Preliminaries.}



%\begin{align}
%	0 = \min\{l(x) - V(xt, x), \dfrac{\partial V}{\partial t} + \max_{u\in \mathcal{U} \nabla_x^T V f(t, x, u) \}
%\end{align}


%The solutions of conservation laws are equivalent to the derivatives of the solutions of HJ PDEs~\cite{OsherFronts}. Therefore, we employ Courant-Lax-Friedrichs approximations~\cite{CrandallLaxFriedrichs} to Hamiltonians to  guarantee numerical stability during computation of control laws, and we leverage techniques from level sets methods~\cite{LevelSetsBook} such as upwinding and HJ essentially non-oscillatory numerical flux schemes for discretized conservation laws to provide better numerical approximations of the spatial derivatives of the dynamic programming  value function.. We know that Hamilton-Jacobi equations in one spatial dimensions are integrals of conservation laws, we leverage the weighted essentially non-oscillatory (ENO) ~\cite{OsherFronts, LevelSetsBook} to extend the ENO method for the numerical discretization of conservation laws to Hamilton-Jacobi equations that are represented by the basic advection equation (to be introduced shortly).

