\section{Backward Reachability for Systems Verification.}
\label{sec:related}
%\subsection{Dynamic Programming and Two-Person Games.}

%\noindent %he formal relationships between the dynamic programming (DP) optimality condition for the \textit{value} in differential two-person zero-sum games, and the solutions to PDEs that solve ``min-max" or ``max-min" type nonlinearity (the Isaacs' equation) was presented in~\cite{Isaacs1965}. 
%With Isaacs' construction~\cite{Isaacs1965}, if \textit{value} functions are smooth enough over a \textit{vectogram}\footnote{Isaac's preferential treatment of a state space as a vectogram is hardly used nowadays, so we adopt the more general term \textit{state space} henceforward.}, then they solve certain first-order partial differential equation (PDE) problems with  ``max-min" or ``min-max"-type nonlinearity.  However, the DP value functions are seldom regular enough to admit a solution in the classical sense.  ``Weaker" solutions on the other hand~\cite{Lions1982, Evans1984, Crandall1984, CrandallLaxFriedrichs, Souganidis} provide generalized ``viscosity" solutions to HJ PDEs under relaxed regularity conditions; these viscosity solutions are not necessarily differentiable anywhere in the state space, and the only regularity prerequisite in the definition is continuity~\cite{Crandall1983viscosity}. However, wherever they are differentiable, they satisfy the  upper and lower values of HJ PDEs in a classical sense. Thus, they lend themselves well to many real-world problems existing at the interface of discrete, continuous, and hybrid systems~\cite{LygerosReachability, OsherFronts, Mitchell2020, Souganidis, Mitchell2005}. Matter-of-factly, viscosity solutions to \textit{Cauchy-type} HJ Equations admit usefulness in backward reachability analysis~\cite{Mitchell2005}. In scope and focus, this is the bulwark upon which we build our formulation.

\begin{comment}
\subsection{System Dynamics.}
For a state $\state \in \openset$ and a fixed time $t$: $0 \le t < T$, suppose that the set of all controls for players $\pursuer$ and $\evader$ are respectively
%
\begin{align}
	\mathcal{\bar{U}} &\equiv \{\bm{u}: [t, T] \rightarrow \mathcal{U} | \bm{u} \text{ measurable}, \, \mathcal{U} \in \bb{R}^m \}, \\
	\mathcal{\bar{V}} &\equiv \{\bm{v}: [t, T] \rightarrow \mathcal{V} | \bm{v} \text{ measurable},  \,\mathcal{V} \subset \reline^p\}.
\end{align}
%
\noindent We are concerned with the  differential equation,
%
\begin{subequations}
	\begin{align}
		\dot{\state}(\tau) &= f(\tau, \state(\tau), \bm{u}(\tau), \bm{v}(\tau)) \quad T \le \tau \le t, \quad \state(t) = \state,
	\end{align}
	\label{eq:sys_dyn}
\end{subequations}
%
\noindent where $f(\tau, \cdot, \cdot, \cdot)$ and $\state(\cdot)$ are bounded and Lipschitz continuous. This bounded Lipschitz continuity property assures uniqueness of the system response $\state(\cdot)$ to controls $\bm{u}(\cdot)$ and $\bm{v}(\cdot)$~\cite{Souganidis}. %,  and we note that a single player definition is defined in~\cite{LygerosReachability}. 
%
Associated with \eqref{eq:sys_dyn} is the payoff functional %for the problem of Bolza, 
%
\begin{align}
	\bm{P}(\bm{u}, \bm{v}) &=	\bm{P}(t; \state, \bm{u}(\cdot), \bm{v}(\cdot)) 
	= \int_{t}^{T} l(\tau, \state(\tau), \bm{u}(\tau), \bm{v}(\tau)) d\tau + g(\state(T)),
	\label{eq:payoff}
\end{align}
%
where $g(\cdot): \bb{R}^n \rightarrow \bb{R}$ %is bounded from above and  Lipschitz continuous \ie it 
satisfies
%
\begin{subequations}
	\begin{align}
		| g(\state) | &\le k_1, \quad
		| g(\state) - g(\hat{\state}) \mid \le k_1 | \state - \hat{\state} \mid
	\end{align}
\end{subequations}
%
and $l:[0, T] \times  \reline^n \times \mathcal{U} \times \mc{V} \rightarrow \bb{R}$ is bounded and uniformly continuous:
%
\begin{subequations}
	\begin{align}
		\mid l(t; \state, \control, \disturb) \mid &\le k_2, \quad
		\mid l(t; \state, \control, \disturb)  -  l(t; \hat{\state}, \control, \disturb) \mid  \le k_2 \mid \state - \hat{\state} \mid
	\end{align}
\end{subequations}
%
for constants $k_1, k_2$ and all 
$0 \le t \le T$, $\hat{\state}, \, \state \in \reline^n$, $\bm{u}\in \mathcal{U}$ and $\disturb \in \mathcal{V}$. 
We call $T$ the \textit{terminal time} (it may be infinity!) and the integral, when it does not depend on the control laws, is the \textit{performance index}. The evader's goal is to maximize the payoff \eqref{eq:payoff} and pursuer's goal is to minimize it. %Henceforward, we refer to $\bm{V}$ as the value.
\end{comment}


\begin{comment}
\subsection{A Two-Person Differential Game and its Viscosity Solution.}
%
%
A similar argument applies to the upper value and we refer readers to \cite{Evans1984, Crandall1983viscosity, Souganidis} for a more detailed treatment. 

\begin{lemma}
	The lower value $\lowervalue$ in \eqref{eq:value_lower} is the viscosity solution to the lower Isaac's equation 
	%
	\begin{subequations}
		\begin{align}
			&\frac{\partial \lowervalue}{\partial t} + \lowerham (t; \state, \bm{u}, \bm{v}, \lowervalue_{\state}) = 0, \,\, t\in \left[0, T\right]\, \state \in \ren  \\
			&\lowervalue(\state, T) = g(x(T)), \quad \state \in \reline^m
			\label{eq:lower_visc_boundary}
		\end{align}
		\label{eq:lower_visc}
	\end{subequations}
	%
	with lower Hamiltonian, 
	%
	\begin{align}
		&\lowerham (t; \state, \bm{u}, \bm{v}, p) = \max_{u \in \mathcal{U}} \min_{v \in \mathcal{V}} \, \langle f(t; \state, \bm{u}, \bm{v}), p  \rangle.
		\label{eq:lower_visc_ham}
	\end{align}
	%
	where $p$, the co-state, is the spatial derivative of $\lowervalue$ w.r.t $\state$.
	\label{lemma:lower_visc_lemma}
\end{lemma}
%
% since we are concerned with the lower value of the differential game in backward reachability analysis, which is the foundation of our work here.
%
%Similarly, suppose that  the evader's mapping strategy (starting at $t$) is $\alpha: \mathcal{\bar{V}}({t}) \rightarrow \mathcal{\bar{U}}({t})$ provided for each $t \le \tau \le T$ and $\bm{v}, \hat{\bm{v}} \in \mathcal{\bar{V}}({t})$; then  $\bm{v}(\bar{t}) = \hat{\bm{v}}(\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$ implies $\alpha[\bm{v}](\bar{t}) = \alpha[\hat{\bm{v}}](\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$. The differential game's upper value for a solution $\bm{x}(t)$ that solves \eqref{eq:sys_dyn} for $\bm{u}(t) = \alpha[\bm{v}](\cdot)$ and $\bm{v}(t)$  is 
%%
%\begin{align}
%	&\uppervalue(\state, t) = \sup_{\alpha \in \mathcal{A}(t)} \inf_{\bm{v} \in \mathcal{V}(t)}  \bm{P}(\alpha[\bm{v}], \bm{v}) \nonumber \\
%	&=  \sup_{\alpha \in \mathcal{A}(t)} \inf_{v \in \mathcal{V}(t)} %\left\{
%	\int_{t}^{T}l(\tau, \bm{x}(\tau), \alpha[\bm{v}](\tau), \bm{v}(\tau)) d\tau  + g\left(\bm{x}(T)\right).
%	\label{eq:value_upper}
%\end{align}
%
The non-local PDE of \ie \eqref{eq:value_lower} is hardly smooth throughout the state space so that it  lacks classical solutions even for smooth Hamiltonian and boundary conditions. However, the value function is the ``viscosity" (generalized)  solutions~\cite{Lions1982, Crandall1983viscosity} of the associated HJ-Isaacs (HJI) PDE. These solutions are \textit{locally Lipschitz} in $\openset \times [0, T]$, and possess at most first-order partial derivatives in the Hamiltonian. 
%
\end{comment}


%\subsection{Backward Reachability for Systems Verification.}
\begin{comment}
	\noindent Reachability analysis is one of many verification methods that allows us to reason about (control-affine) dynamical systems. %For CPS systems, the scalability of existing verification methods is a requirement for the proper verification of complex systems.  
		
	%Reachability for continuous or hybrid systems can be framed within the framework of differential control theory, whose solution can be characterized by variants of Hamilton-Jacobi-Isaacs (HJI) PDEs: \textit{from a set of initial and unsafe state sets, and a time bound, the time-bounded safety verification problem is to determine if there is an initial state and a time within the bound that the solution to the PDE enters the unsafe set}. 
	Reachability could be analyzed in a 
	%
	\begin{itemize}%[(i)]
		\item \textit{forward} sense, whereupon system trajectories are examined to determine if they enter certain states from an \textit{initial set};
		%
		\item \textit{backward} sense, whereupon system trajectories are examined to determine if they enter certain \textit{target sets};
		%
		\item \textit{reach set} sense, in which they are examined to see if states reach a set at a \textit{particular time}; or
		%
		\item \textit{reach tube} sense, in which they are evaluated that they reach a set at a point \textit{during a time interval}.	
	\end{itemize} 
 With the \textsc{inf-sup} construction above, it is easy to cast the two-person game into a verification problem, whereupon we discard the stage cost and resolve the safety verification problem by solving for the terminal cost.
\end{comment}

\noindent A basic characteristic of a control system is to determine the  point sets within the state space that are \textit{reachable} with a control input choice. An example objective in \textit{reachability analysis} could be a target ($\targetset$) protection objective by an evading player, $\evader$, from a pursuing player $\pursuer$. Our treatment here is a special case of Isaac's homicidal chauffeur's game~\cite{Isaacs1965}, whereupon a $\pursuer$ and $\evader$ travel at a constant linear speeds but have different headings, \eg where the $\pursuer$ seeks to drive an evader, $\evader$, into a target (or target set/tube), $\targetset$. When resolving the 
outcome of the game, a notion of \textit{payoffs} is used. The payoff could be the distance from the target to the point/region of capture. 

\textit{Backward reachability} consists in avoiding an unsafe set of states under the worst-possible disturbance and at all times. The verification problem may consist in finding a \textit{set of reachable states} that lie along the trajectories of the solution to a first order nonlinear P.D.E. that originates from some initial state $\state_0 = \state(0)$ up to a specified time bound, $t=t_f$. \textit{From a set of initial and unsafe state sets, and a time bound, the time-bounded safety verification problem is to determine if there is an initial state and a time within the bound that the solution to the P.D.E. enters the unsafe set}.
 
Backward reachable sets (BRS) or tubes (BRTs) are popularly analyzed as a game of two vehicles with non-stochastic dynamics~\cite{Merz1972}. Such BRTs possess discontinuity at cross-over points (which exist at edges) on the surface of the  tube, and may be non-convex. Mitchell's construction~\cite{Mitchell2005} does not necessarily use a state feedback control law during games and the worst-possible disturbance assumption is not formally inculcated in the backward reachability analyses used. In a sense, it is reasonable to ignore nonlinear robust control (\eg $\mathcal{H}_\infty$) analyses for Dubins vehicles~\cite{Dubins1957} with constant inputs that only vary in sign for either player \cite{Merz1972} since the worst possible disturbance is known ahead of the game. In realistic problems, one may  leverage an $\mathcal{H}_\infty$ scheme~\cite{DoyleBook}'s  in constructing an appropriate \textit{worst-possible} disturbance that  guarantees robustness in continuous control applications. We leave this to a future work. %Therefore, treating the end-point constraints under these discontinuity characterizations need careful consideration and analysis when switching control laws if the underlying P.D.E does not have continuous partial  derivatives (we discuss this further in section \ref{sec:methods}). 

\subsection{Reachability from Differential Games Optimal Control}

\noindent   In general, we seek for a \textit{terminal payoff} $g(\cdot): \bb{R}^n \rightarrow \bb{R}$ to satisfy
%
\begin{subequations}
	\begin{align}
		| g(\state) | &\le k, \quad | g(\state) - g(\hat{\state}) \mid \le k | \state - \hat{\state} \mid
	\end{align}
\end{subequations}
%
for constant $k$ and all $T \le t \le 0$, $\hat{\state}, \, \state \in \reline^n$, $\bm{u}\in \mathcal{U}$ and $\disturb \in \mathcal{V}$.  The zero sublevel set of $g(\state)$ is
%
\begin{align}
	\mathcal{L}_0 = \{ \state \in \bar{\Omega} \,|\, g(\state) \le 0 \}.
	\label{eq:target_set_syk}
\end{align}

Suppose that the pursuer's mapping strategy (starting at $t$) is $\beta: \mathcal{\bar{U}}({t}) \rightarrow \mathcal{\bar{V}}({t})$ provided for each $t \le \tau \le T$ and $\bm{u}, \hat{\bm{u}} \in \mathcal{\bar{U}}({t})$; then $\bm{u}(\bar{t}) = \hat{\bm{u}}(\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$ implies $\beta[\bm{u}](\bar{t}) = \beta[\hat{\bm{u}}](\bar{t}) \,\, \text{ a.e. on } t \le \bar{t}  \le \tau$. \textit{The player $\pursuer$ is controlling the strategy $\beta$ and minimizing}, while the \textit{player $\evader$ is controlling its strategy, $\alpha$, and maximizing}. %While the terms pursuer and evader
%
The differential game's lower value for a solution $\state(t)$ that solves \eqref{eq:sys_dyn} for $\bm{u}(t)$ and $\bm{v}(t) = \beta[\control](\cdot)$ is 
%
\begin{align}
	&\lowervalue(\state, t) = \inf_{\beta \in \mathcal{B}(t)} \sup_{\bm{u} \in \mathcal{U}(t)} \bm{P}(\bm{u}, \beta[\bm{u}]) \nonumber \\
	&=  \inf_{\beta \in \mathcal{B}(t)} \sup_{\bm{u} \in \mathcal{U}(t)} %\left\{
	\int_{t}^{T} l(\tau, \bm{x}(\tau), \bm{u}(\tau), \beta[\bm{u}](\tau)) d\tau + g\left(\bm{x}(T)\right). %
	\label{eq:value_lower}
\end{align}
%
%We now establish the following Lemma from~\cite{Souganidis} that will aid the construction of the \textit{robustly controlled backward reachable tube} -- our main emphasis in this paper. 
%
%\begin{lemma}
%	The lower value $\lowervalue$ of a differential game's terminal cost problem is the viscosity solution to the lower Isaac's equation 
%	%
%	\begin{subequations}
%		\begin{align}
%			&\frac{\partial \lowervalue}{\partial t} + \lowerham (t; \state, \bm{u}, \bm{v}, \lowervalue_{\state}) = 0, \,\, t\in \left[0, T\right]\, \state \in \ren  \\
%			&\lowervalue(\state, T) = g(x(T)), \quad \state \in \reline^m
%			\label{eq:lower_visc_boundary}
%		\end{align}
%		\label{eq:lower_visc}
%	\end{subequations}
%	%
%	with lower Hamiltonian, 
%	%
%	\begin{align}
%		&\lowerham (t; \state, \bm{u}, \bm{v}, p) = \max_{u \in \mathcal{U}} \min_{v \in \mathcal{V}} \, \langle f(t; \state, \bm{u}, \bm{v}), p  \rangle.
%		\label{eq:lower_visc_ham}
%	\end{align}
%	%
%	where $p$, the co-state, is the spatial derivative of $\lowervalue$ w.r.t $\state$.
%	\label{lemma:lower_visc_lemma}
%\end{lemma}
%%
%\begin{proof}
%	This lemma is an adaptation of \cite[Th 4.1]{Souganidis}.
%\end{proof}

For any admissible control-disturbance pair $(\bm{u}(\cdot), \bm{v}(\cdot))$ and initial phase $(\state_0, t_0)$, Crandall~\cite{Crandall1983viscosity} and Evan's~\cite{Evans1984} claim is that there exists a unique function % $\xi(t)$  
%
\begin{align}
	\bm{\xi}(t) = \bm{\xi}(t; t_0, \state_0, \bm{u}(\cdot), \bm{v}(\cdot))
	\label{eq:HJ_traj}
\end{align}
%
that satisfies 
%
\begin{subequations}
	\begin{align}
		\dot{\state}(\tau) &= f(\tau, \state(\tau), \bm{u}(\tau), \bm{v}(\tau)) \quad T \le \tau \le t, \quad \state(t) = \state,
	\end{align}
	\label{eq:sys_dyn}
\end{subequations}
%
\noindent where $f(\tau, \cdot, \cdot, \cdot)$ and $\state(\cdot)$ are bounded and Lipschitz continuous. This bounded Lipschitz continuity property assures uniqueness of the system response $\state(\cdot)$ to controls $\bm{u}(\cdot)$ and $\bm{v}(\cdot)$~\cite{Souganidis}. 
%
a.e. with the property that
%
\begin{align}
	\bm{\xi}(t_0) = \bm{\xi}(t_0; t_0, \state_0, \bm{u}(\cdot), \bm{v}(\cdot)) = \state_0.
\end{align}
%
Read \eqref{eq:HJ_traj}: the motion of \eqref{eq:sys_dyn} passing through phase $(\bm{x}_0, t_0)$ under the action of control $\bm{u}$, and disturbance $\bm{v}$, and observed at a time $t$ afterwards. One way to design a system verification problem is compute the reachable set of states that lie along the trajectory \eqref{eq:HJ_traj} such that we evade the unsafe sets up to a time \eg $t_f$ within a given time bound  $\left[t_0, t_f\right]$. In this regard, we discard \eqref{eq:value_lower}'s \textit{cost-to-go} and certify safety as resolving a time-bounded terminal value, $g(\state(T))$ at time $T$ up to a final time \eg $0$.

%In backward reachability analysis, the lower value of the differential game~\cite{Souganidis} is used in constructing an analysis of the backward reachable set (or tube). Therefore, we can cast a target set as the time-resolved terminal value $\lowervalue(\state, T) = g(\state(T))$ so that given a time bound, and an unsafe set of states, the time-bounded safety verification problem consists in certifying that there is no phase within the target set \eqref{eq:target_set} such that the solution to \eqref{eq:sys_dyn} enters the unsafe set. 

\begin{lemma}
	The backward reachability problem on the resolution of the infimum-supremum over the \textit{non-anticipative strategies} of $\pursuer$ and the \textit{controls} of $\evader$ with the time of capture resolved as an extremum of the cost functional over a time interval is given by %~\cite{LygerosReachability}. 
	\begin{subequations}
		\begin{align}
			\frac{\partial \lowervalue}{\partial t}{(\bm{x}, t)} & + \min \{0, \lowerham (t; \bm{x}, \bm{u}, \bm{v},\lowervalue_{\state}) \} = 0, \, \state \in \ren, t \in \left[-T, 0\right]\\
			%
			\lowervalue(\bm{x},0) &= g(\bm{x}), \\
%		\end{align}
%	\end{subequations}
%	&\text{ where } %the Hamiltonian is defined as} \nonumber \\
%	%
%	\begin{align}
	\text{ where } 	\lowerham (t; \state, \bm{u}, \bm{v}, p) &= \max_{u \in \mathcal{U}} \min_{v \in \mathcal{V}} \, \langle f(t; \state, \bm{u}, \bm{v}), p  \rangle,
		\label{eq:lower_visc_ham}
	\end{align}
	\label{eq:lower_hji_pde}
	\end{subequations}
	%
	and $p$, the co-state, is the spatial derivative of $\lowervalue$ w.r.t $\state$.
	%
	\noindent where the vector field $\lowervalue_{\state}$ is known in terms of the game's terminal conditions so that the overall game is akin to a two-point boundary-value problem.
	\label{lemma:rcbrt}
\end{lemma} 
%
\noindent Henceforward, for ease of readability, we will remove the minus superscript on the lower value and Hamiltonian \eqref{eq:lower_visc_ham}. 
%
\begin{proof}
	%
	Lemma \ref{lemma:rcbrt} is an adaptation of ~\cite{Mitchell2005}.
\end{proof}

%\begin{lemma}
%	The lower value $\lowervalue$ of a differential game's terminal cost problem is the viscosity solution to the lower Isaac's equation 
%	%
%	\begin{subequations}
%		\begin{align}
%			&\frac{\partial \lowervalue}{\partial t} + \lowerham (t; \state, \bm{u}, \bm{v}, \lowervalue_{\state}) = 0, \,\, t\in \left[-T, 0\right]\, \state \in \ren  \\
%			&\lowervalue(\state, T) = g(x(T)), \quad \state \in \reline^m
%			\label{eq:lower_visc_boundary}
%		\end{align}
%		\label{eq:lower_visc}
%	\end{subequations}
%	%
%	whose Hamiltonian is, 
%	%
%	\begin{align}
%		&\lowerham (t; \state, \bm{u}, \bm{v}, p) = \max_{u \in \mathcal{U}} \min_{v \in \mathcal{V}} \, \langle f(t; \state, \bm{u}, \bm{v}), p  \rangle.
%		\label{eq:lower_visc_ham}
%	\end{align}
%	%
%	where $p$, the co-state, is the spatial derivative of $\lowervalue$ w.r.t $\state$.
%	\label{lemma:lower_visc_lemma}
%\end{lemma}
%
%\begin{proof}
%	This lemma is an adaptation of \cite[Th 4.1]{Souganidis}.
%\end{proof}

In the sentiment of \cite{Mitchell2005}, we say the zero sublevel set of $g(\cdot)$ in \eqref{eq:lower_hji_pde} \ie $\mathcal{L}_0 = \{ \state \in \bar{\Omega} \,|\, g(\state) \le 0 \},$
%
%\begin{align}
%	\mathcal{L}_0 = \{ \state \in \bar{\Omega} \,|\, g(\state) \le 0 \},
%	\label{eq:target_set}
%\end{align}
%
is the \textit{target set} in the phase space $\openset \times \mathbb{R}$ for a backward reachability problem. This target set can represent the failure set, regions of danger, or obstacles to be avoided etc in the state space. Note that the target set, $\mathcal{L}_0$, is a closed subset of $\ren$ and is in the closure of $\openset$. And the \textit{robustly controlled backward reachable tube} for $\tau \in [-T, 0]$\footnote{The (backward) horizon, $-T$ is negative for $T>0$.} is the closure of the open set
%
\begin{align}
	\mathcal{L}([\tau, 0], \mathcal{L}_0) &= \{\state \in \openset \,| \, \exists \, \beta \in \mathcal{\bar{V}}(t) \,  \forall \, \bm{u} \in \mathcal{U}(t), \exists \, \bar{t} \in [-T, 0], \nonumber \\
	& \qquad  \qquad \bm{\xi}(\bar{t})%\left(t; \state_0, t_0, \bm{u}(\cdot), \beta[\bm{u}](\cdot) \right)
	\in  \mathcal{L}_0 \}, \,\bar{t} \in \left[-T, 0\right].
	\label{eq:rcbrt}
\end{align}
%
Read: the set of states from which the strategies $\beta$ of $\pursuer$, and for all controls $\mc{U}(t)$ of $\evader$ imply that we reach the target set within the interval $[-T, 0]$.   More specifically, following Lemma 2 of \cite{Mitchell2005}, the states in the reachable set admit the following properties w.r.t the value function $\valuefunc$
%
%\begin{subequations}
	\begin{align}
		\state \in \mathcal{L}_0 &\implies \lowervalue(\state, t) \le 0 \text{ and }		\lowervalue(\state, t) \le 0 &\implies \state \in \mathcal{L}_0.
	\end{align}
%\end{subequations}
%
%Observe:
%%
%\begin{itemize}
%	\item The goal of the pursuer, or $\pursuer$, is to drive the system's trajectories into the unsafe set i.e., $\pursuer$ has $\control$ at will and aims to minimize the termination time of the game  (c.f. \eqref{eq:target_set});
%	%
%	\item The evader, or $\evader$, seeks to avoid the unsafe  set i.e., $\evader$ has controls $\disturb$ at will and seeks to maximize the termination time of the game (c.f.  \eqref{eq:target_set});
%	%
%	\item $\evader$ has regular controls, $\bm{u}$, drawn from a Lebesgue measurable set, $\mathcal{U}$ (c.f. \eqref{eq:value_lower});
%	%
%	\item $\pursuer$ possesses \textit{nonanticipative strategies} (c.f. \eqref{eq:value_lower}) \ie  $\beta[\bm{u}](\cdot)$ such that for any of the ordinary controls, $\bm{u}(\cdot) \in \mathcal{U}$ of $\evader$, $\pursuer$ knows how to optimally respond to $\evader$'s inputs.
%\end{itemize}
%
% The order of play is non-consequential because: 
%
%\begin{itemize}		
%	%
%	\item I's \textit{strategy} can instantaneously respond to any choice of II's controller, regardless of I playing first;
%	%
%	%\item If we follow Merz's example~\cite{Merz1972} of putting I at the origin, and it plays first, either player knows what I's response will be to any input of II. 
%	%
%	\item Under I's nonanticipative strategy, the value of the game  is always less than the value under state feedback so that this choice mitigates underapproximation of the state feedback reachable set~\cite{Mitchell2005}.
%\end{itemize}
%
%\todo{We obtain a \textit{pseudo iterative dynamic game}~\cite{iDG}, albeit in open-loop settings, where either player infers the current state useful enough for generating closed-loop input control laws.} 
%An implicit surface function, $\{\lowervalue{(\state, t)}: \left[-T, 0\right] \times \mathcal{X}\rightarrow\mathbb{R}, \, \forall \, t>0\}$ \ie the terminal value $\lowervalue {(\state, t)}$, that characterizes the target set $\targetset_0$ is the viscosity solution to the HJI PDE
%


%\begin{align}
%	0 = \min\{l(x) - V(xt, x), \dfrac{\partial V}{\partial t} + \max_{u\in \mathcal{U} \nabla_x^T V f(t, x, u) \}
	%\end{align}
	
	
	%The solutions of conservation laws are equivalent to the derivatives of the solutions of HJ PDEs~\cite{OsherFronts}. Therefore, we employ Courant-Lax-Friedrichs approximations~\cite{CrandallLaxFriedrichs} to Hamiltonians to  guarantee numerical stability during computation of control laws, and we leverage techniques from level sets methods~\cite{LevelSetsBook} such as upwinding and HJ essentially non-oscillatory numerical flux schemes for discretized conservation laws to provide better numerical approximations of the spatial derivatives of the dynamic programming  value function.. We know that Hamilton-Jacobi equations in one spatial dimensions are integrals of conservation laws, we leverage the weighted essentially non-oscillatory (ENO) ~\cite{OsherFronts, LevelSetsBook} to extend the ENO method for the numerical discretization of conservation laws to Hamilton-Jacobi equations that are represented by the basic advection equation (to be introduced shortly).