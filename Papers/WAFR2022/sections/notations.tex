\section{Notations and Definitions.}
\label{sec:notations}

Let us now introduce the notations that are commonly used in this article. 
Time variables \eg $t, t_0, \tau, T$ will always be  real numbers. We let $t_0 \le t \le t_f$ denote fixed, ordered values of $t$. Vectors shall be column-wise stacked and be denoted by small bold-face letters \ie $\mathbf{e}, \mathbf{u}, \mathbf{v}$  e.t.c. %When we refer to a row-vector, we shall introduce the transpose as a superscript operator \ie  $\bm{x}^T$. 
Matrices  will  be denoted by bold-math Latin  upper case  fonts  e.g. $\mathbf{T}, \mathbf{S}$.  %We designate uppercase letters $I, \, N, \, R$ for tensor sizes (the total number of elements encompassed along a dimension of a tensor), and lowercase letters $i, \, n,  \, r$ for corresponding tensor indices. 
Exceptions: the unit matrix is $\identity$; and $i,j,k,p$ are indices.  We adopt zero-indexing for matrix operations throughout so that if index $i$ corresponds to size $N$, we shall write $i = 0, 1, \cdots , N-1$. %Lastly, for a tensor with $N$ modes, we denote by $\left[N\right]$ the set $\left\{0,1,\cdots,N-1\right\}$.
Positive, negative, increasing, decreasing  e.t.c. shall refer to strict corresponding property.
%
%A \textit{basis} for a \textit{vector space} $\mathbb{E}$ is a set of three linearly independent vectors. An \textit{orthonormal basis} is a set of three vectors, $\{\mathbf{e}_i\}_{i=1}^3$, such that $\mathbf{e}_i \cdot \mathbf{e}_j = \delta_{ij}$,
%
%\begin{align}
%    \mathbf{e}_i \cdot \mathbf{e}_j = \delta_{ij} = \begin{cases}
	%        1 \quad i=j, \\
	%        0 \quad i \neq j,
	%    \end{cases}
%\end{align}
%
%where $\delta_{ij}$ is the Kr\"{o}necker delta symbol. %The orthonormal basis set $\{\mathbf{e}_i\}$ forms the right-handed triad of unit vectors, $\mathbf{e}_i \wedge \mathbf{e}_j =  \mathcal{E}_{ijk} \mathbf{e}_k$,
%
%\begin{align}
%    \mathbf{e}_i \wedge \mathbf{e}_j =  \mathcal{E}_{ijk} \mathbf{e}_k,
%\end{align}
%
%where $\wedge$ denotes the vector product and $\mathcal{E}_{ijk}$ is the \textit{alternating symbol},
%%
%\begin{align}
%	\mathcal{E}_{ijk} = 
%	\begin{cases}
	%		+1  \text{ if $(ijk)$ is a cyclic permutation of (123)}; \\
	%		-1 \text{ if $(ijk)$ is an anticyclic permutation of (123)}; \\
	%		\,\, 0 \text{ otherwise. }
	%	\end{cases}
%\part{title}%	\label{eq:alt_symbol}
%\end{align}
\begin{comment}
\subsection{Vectors and Matrices.}
%
 The norm $\|\mathbf{X}\|$ of a matrix $\mathbf{X}$ is $\text{sup } \|\mathbf{X}\|$ over $\|\mathbf{X}\|=1$.   We define the \textit{direction cosines} of the orthonormal basis $\{\basis_i^\prime\}$ oriented with respect to $\{\mathbf{\basis}_j\}$ as $ \mathbf{Q}_{ij} = \mathbf{\basis}_i^\prime \cdot \mathbf{\basis}_j.$
%
%\begin{align}
%    Q_{ij} = \basis_i^\prime \cdot \mathbf{e}_j.
%\end{align}
%
so that by orthonormality and by $\basis_i^\prime = \mathbf{Q}_{ik} \basis_k \, \forall i=(1, 2, 3)$, we have  $\delta_{ij} = \basis_i^\prime \cdot \basis_j^\prime = \mathbf{Q}_{ik} \, \basis_k \cdot \basis_j^\prime = \mathbf{Q}_{ik} \mathbf{Q}_{jk}$, where $\delta_{ij}$ is the Kr\"{o}necker delta symbol.
%
%\begin{align}
%    \delta_{ij} = \basis_i^\prime \cdot \basis_j^\prime = Q_{ik} \, \basis_k \cdot \basis_j^\prime = Q_{ik} Q_{jk}. 
%\end{align}
%
%More generally, 
%%
%\begin{align}
%    \delta_{ij} =  Q_{ik} Q_{jk} = Q_{ki} \, Q_{kj}.
%\end{align}
%
The \textit{triple scalar product}  $\left( \mathbf{u} \wedge \mathbf{v} \right) \cdot \mathbf{w}$ is $\left(\mathcal{E}_{ijp} u_i v_j \mathbf{e}_p \right) \cdot \left( w_k \basis_k \right) = \mathcal{E}_{ijk} u_i v_j w_k$, where $\mathcal{E}_{ijk}$ is the \textit{alternating symbol}.
%
%\begin{align}
%    \left(\mathcal{E}_{ijp} u_i v_j \mathbf{e}_p \right) \cdot \left( w_k \mathbf{e}_k \right) = \mathcal{E}_{ijk} u_i v_j w_k,
%\end{align}
%https://www.overleaf.com/project/615c594d6747b57ebc1f3987
% where the $\wedge$ operator denotes the vector product. 
%We will represent the set of direction cosines $Q_{ij}$ as $Q$ so that $Q$ is an orthogonal matrix $Q \, Q^T = \identity =  Q \, Q^T$. In this vein, it is trivial to verify that moving between bases is tantamount to $\basis_i^\prime = Q_{ij} \basis_j$ and $\basis_j = Q_{ij} \basis_i^\prime$. 
%
For two vectors $\mathbf{u}$ and $\mathbf{v}$ moving between bases $\{\basis_i\}$ and $\{\basis_i^\prime\}$, their components' product $u_i v_j$ transform according to the tensor product\footnote{Or the dyadic product.}, $(\mathbf{u} \otimes \mathbf{v})_{ij} = u_i^\prime v_j^\prime = \mathbf{Q}_{ip} \mathbf{Q}_{jq} u_p v_q$. Thus, $\identity = \delta_{ij} \basis_i \otimes \basis_j:= \basis_i \otimes \basis_j$ for an arbitrary orthonormal basis $\{\basis_i \}$.

\subsubsection{Tensors:}
%
We refer to the \textit{mode-$n$ unfolding} (or \textit{matricization}) of a tensor, $\mathds{T}$, as the rearrangement of its $N$ elements into a matrix, $\mathds{T}_{n} \in \mathbb{R}^{I_n \times \Pi^{n-1}_{k\neq n} I_k}$  where $n \in \{0, 1, \cdots, N-1\}$. The \textit{multilinear rank}  of $\mathds{T} \in \reline^{I_0 \times I_1 \cdots \times I_{N-1}}$ is an $N$-tuple with elements that correspond to the rank of the mode-$n$ vector space i.e., $\left(R_0, R_1, \cdots, R_{N-1}\right)$. The \textit{Frobenius inner product} induced on the  tensor product space $\mathds{T}_1 \oti~\cite{Crandall1984Approx}mes \mathds{T}_2 \, \in \reline^{I_0 \times I_1 \times I_{n-1} \cdots \times I_{N-1}}$ is 
%
\begin{align}
	\langle \mathds{T}_1, \mathds{T}_2 \rangle_F &= \text{trace} \left(\mathds{T}_{2_{(n)}}^T, \mathds{T}_{1_{(n)}} \right) 
	%
	= \text{trace} \left(\mathds{T}_{1_{(n)}}^T, \mathds{T}_{2_{(n)}} \right) %\label{eq:hilbert-schmidt-inner-product} \\
	= \langle \mathds{T}_2, \mathds{T}_1 \rangle_F. \label{eq:hilbert-schmidt-inner-product} 
\end{align}
%
% (the Frobenius norm of tensor $\mathds{T}$)
By the \textit{norm of a tensor} with dimension $N$, we shall mean the square root of the sum of squares of all its elements. This is equivalent to the Frobenius norm along any $n$-mode unfolding, $\mathds{T}_{(n)}$, of tensor $\mathds{T}$. Thus, 
%
\begin{align}
	\|\mathds{T}\|_F^2 := \langle \mathds{T}, \mathds{T} \rangle_F = \|\mathds{T}_{(n)}\|^2_F
\end{align}
%
for any $n$-mode unfolding of the tensor. We may otherwise refer to  $\|\cdot \|_F$ as the Hilbert-Schmidt norm. 

Following the convention delineated in \autoref{table:defos}, we define the product of tensor $\mathds{T}$ (of size $I_0 \times I_1 \times I_{n-1} \cdots \times I_{N-1}$) and a matrix $\mathbf{U}$ (of size $J \times I_n$) as
%
\begin{align}
	\mathds{P} = \mathds{T} \otimes_n \mathbf{U} \implies \mathds{P}_{(n)} = \mathbf{U}  \mathds{T}_{(n)}.
	\label{eq:ttm}
\end{align}
%
For different modes, the ordering of the modes is not consequential so that 
%
\begin{align}
	\mathds{T} \otimes_n \mathbf{U} \otimes_m \mathbf{V} = \mathds{T} \otimes_m \mathbf{V} \otimes_n \mathbf{U} \quad \forall \, m \neq n.
\end{align}
%
However, in the same mode, order matters so that $\mathds{T} \otimes_n \mathbf{U} \otimes_n \mathbf{V} = \mathds{T} \otimes_n \mathbf{V} \, \otimes_n \, \mathbf{U}$. The \textit{multilinear orthogonal projection} from a tensor space with dimension 
\[
{I_0 \times \cdots I_{n-1}  \times I_n \\ \times I_{n+1} \cdots \times I_{N-1}}
\] onto the subspace ${I_0 \times \cdots I_{n-1}  \times U_n \times I_{n+1} \cdots \times I_{N-1}}$ is the orthogonal projection along mode $n$ given by
%
\begin{align}
	\pi_n \mathds{T} := \mathds{T}\otimes_n \left(\mathbf{I}-\mathbf{U}_n \mathbf{U}_n^T \right).
\end{align}
%
The rest of the notations we use for tensor operations in this article are described in Table \ref{table:defos}. We refer readers to~\cite{Kolda2009, VannieuwenhovenTruncate2012} for a detailed description of other tensor algebraic notations and multilinear operations. 
\end{comment}

%%
%\begin{table}[tb!]
%	\caption{\textbf{Common Notations}}
%	\footnotesize{
%		\begin{tabular}{ll}
%			%
%			%{ $\mathds{T}_n$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{$n$-mode unfolding of  $\mathds{\mathds{T}}$.} & 
%			{ a.e. }  & \!\! \parbox[c][0.5in][c]{0.4\columnwidth}{Almost everywhere.}  \\
%			%  = \mathds{T}_n \mathds{T}_n^T
%			%{ $\mathbf{G}$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{{Gram matrix}.} & 
%			{ $\bm{\xi}$ }  & \!\! \parbox[c][0.5in][c]{0.4\columnwidth}{System trajectory. % e.g. obtained from integrating $\state$.
%			}  \\
%			%
%			%{ $\left[ N \right] %= \{0, 1, \cdots, N-1\} $ }  	& \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{Total number of modes in $\mathds{T}$.} & 	
%			$\pursuer$, $\evader$  & \!\! \parbox[c][0.2in][c]{0.71\columnwidth}{Pursuer and Evader respectively.} \\
%			%
%			%{ $\|\mathds{T}\|_F$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{The {Hilbert-Schmidt norm} of $\mathds{T}$.} & 
%			{ $\bm{V}(t, \bm{x})$}  & \!\! \parbox[c][0.5in][c]{0.4\columnwidth}{Value function of the differential game.}  \\
%			%
%			%{ $\mathds{T} \otimes_n \mathbf{U}$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{$n$-mode product of $\mathds{T}$ with matrix $\mathbf{U}$.} & 
%			{ $\bm{V}_{\state}, \bm{V}_t$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{$\valuefunc$'s spatial  (resp. time) derivative.}  \\
%			%
%			%{ $\mathds{T}  \hat{\otimes}_n \mathbf{v}$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{$n$-mode product of $\mathds{T}$ with vector $\mathbf{v}$.} & 
%			{ $\valuefunc^\pm$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{Lower(-) or upper(+) values of the differential game.}  \\
%			%
%			%{ $\mathds{T}  \circledast \mathbf{S}$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{Kronecker product of $\mathds{T}$ with matrix $\mathbf{S}$.}  & 	
%			{ $\mathcal{A},\mathcal{B}$} & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{Strategies set for  $\pursuer$ and $\evader$.} \\
%			%
%			%{ $\mathds{T}  \odot \mathbf{S}$ }  & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{Khatri-Rao product of $\mathds{T}$ with matrix $\mathbf{S}$.} & 	
%			{ $\targetset_0(\tau)$} & \!\! \parbox[c][0.3in][c]{0.4\columnwidth}{A game's target set.} 
%			%
%		\end{tabular}
%	}
%	\label{table:defos}
%\end{table}
%
%\subsection{Sets, Controls, and Games.}

 The set $S$ of all $\state$ such that $\state$ belongs to the real numbers  $\bb{R}$, and that $\state$ is positive shall be written as $S=\{\state\,|\, \state \in \bb{R}, \state >0\}$. The cardinality of $S$ shall be written as $\left[S\right]$. We define $\Omega$ as the open set in $\ren$.  To avoid the cumbersome phrase ``the state $\bm{x}$ at time $t$", we will associate the pair $(\bm{x}, t)$ with the \textit{phase} of the system for a state $\bm{x}$ at time $t$. Furthermore, we associate the Cartesian product of $\openset$ and the space $T =\reline^1$ of all time values as the \textit{phase space} of $\openset \times T$. The interior of $\openset$ is denoted by $\text{ int } \openset$; whilst the closure of $\openset$ is denoted $\bar{\openset}$. We denote by $\delta \openset \,(:= \bar{\openset} \backslash \text{int } \openset)$ the boundary of the set $\openset$. 

Unless otherwise stated, vectors $\bm{u}(t)$ and $\bm{v}(t)$ are reserved for admissible control (resp. disturbance) at time $t$. We say $\bm{u}(t)$ (resp. $\bm{v}(t)$) is piecewise continuous in $t$, if for each $t$, $\bm{u} \in \mathcal{U}$ (resp. $\bm{v} \in \mathcal{V}$), $\mathcal{U}(\text{ resp. } \mc{V})$ is a Lebesgue measurable and compact set. At all times, any of $\control$ or $\disturb$ will be under the influence of a \textit{player} such that the motion of a state $\state$ will be influenced by the will of that player. Our operational domain involves conflicting objectives between various agents \eg with a heading convergence goal under an external disturbance' influence. For agents that are members of a local coordination group, collision avoidance shall apply so that  agents within a local neighborhood cooperate to avoid entropy and preying pursuer(s). Thus, the problem at hand assumes that of a pursuit \textit{game}.  And by a game, we do not necessarily refer to a single game, but rather a \textit{collection of games}. Such a game will terminate when \textit{capture} occurs, that is the distance between players falls below a predetermined threshold. 

Each player in a game shall constitute either a pursuer ($\pursuer$) or an evader ($\evader$). The cursory reader should not interpret $\pursuer$ or $\evader$ as controlling a single agent. In complex settings, we may have several pursuers (enemies) or evaders (peaceful citizens). However, when $\pursuer$ or $\evader$ governs the behavior of but one agent, these symbols will denote the agents themselves. %The game shall terminate when a \textit{capture} occurs, and when the distance between $|\pursuer \evader|$ becomes less than a threshold, we shall have a \textit{capture}. 
Given the various possibilities of outcomes, the question of what is ``best" will be resolved by a \textit{payoff}, $\Phi$, whose extremal over a time interval will constitute a \textit{value}, $\valuefunc$\footnote{The functional $\bm{\Phi}$ may be considered a functional mapping from an infinite-dimensional space to the space of real numbers.}. We adopt Isaac's~\cite{Isaacs1965} language so that if the payoff for a game is finite, we shall have a \textit{game of kind}; and for a game with a continuum of payoffs, we shall have \textit{a game of degree}. The \textit{strategy} executed by $\pursuer$ or $\evader$ during a game shall be denoted by $\alpha \in \mc{A}$ (resp. $\beta \in \mc{B}$). With this definition, a control law \eg $\control^{(i)}$ played by a player \eg $\pursuer$ will affect \textit{agent} $i$; and a collection of agents under $\pursuer$'s \textit{willpower} be referred to as a \textit{flock}. We shall refer to an aggregation of flocks on a state space as a \textit{murmuration} \footnote{The definition of murmurations we use here has a semblance to the murmurations of possibly thousands of starlings observed in nature.}.
%