\section{Materials and Methods.}
\label{sec:methods}
%
We focus on the task verification problem, and we resolve the $(n-1) \in \bb{R}^n$-dimensional hypersurfaces  or \textit{interfaces} between flocks using level set methods~\cite{SethianLSBook}. Flocks $\flock_j$ and $\flock_k$ are separated by an interface. This interface is  implicitly represented as a  signed distance function $\payoff(\state)$ that is negative on the interior of one flock, and positive on interior of the other. The zero-level set $\payoff(\state)=0$ corresponds to the original interface $\valuefunc$~\cite{Sethian87Numerical}. Adding time, the motion of the interface (the zero-level set) can then be described by an initial value problem that corresponds to a Cauchy-type Hamilton Jacobi partial differential equation~\cite{Evans1984, Crandall1983viscosity}. 

%	and each region/flock is separately synthesized  via HJI analysis, followed by a repair procedure which reattaches the evolving regions to each other}. As the verification problem is resolved forward in time, control laws permeate payoff boundaries (semi-permeable surfaces). For each flock, there corresponds local value (cost) functionals that encode a desirable anisotropic density and structural pattern we would like to emerge.  These local value functions are constructed by  taking into cognizance each agent's topological interaction rule with its neighbors~\cite{Ballerini1232}. We leave a thorough analysis and evaluation of the nature of the \textit{surfaces}\footnote{Surfaces can be  singular, dispersal, or universal in nature~\cite{Isaacs1965}.} to a future work. These simple tricks allows us to compute large backward reach-avoid tubes.% that have eluded other scalability methods that have been so far introduced~\cite{Bansal, SylviaScalability, DecompChenHerbert}}. 
 
 We locally synthesize the kinematics of agents in a manner amenable to state representation by resolving local payoff extremals -- essentially a state space partition induced by a an aggregation of preexisting desired emergent collective behavior from local flocks\footnote{Let the cursory reader understand that we use the concept of a flock loosely. The value function could represent a pallete of composed value functions whose extremals resolve local behaviors we would like to emerge over separated local regions of the state space of dextrous drone acrobatics~\cite{DeepAcrobatics}, a robot balls juggling task~\cite{SeqCompKoditschek} or any parallel task domain verification problem.}.  Suppose that the local control laws are properly coordinated, the region of the state space across which their coordinated influence might be exerted constitute a larger \eg \textit{manipulability volume} for a dexterous kinematic task. 
 
 \noindent \textbf{Assumptions}:
The many interacting subsystems under consideration employ
 %
 \begin{inparaenum}[(i)]
 	\item natural units of measurements that are the same for all agents; 
 	%
 	\item kinematics with linear speeds but with a capacity for orientation changes;
 	%
 	\item intra-flock agent interaction is restricted within unique and distinct state space manifolds; and by agents maneuvering their direction, a kinematic alignment is obtained;
 	%
 	\item inter-flock interaction occurs when a pursuer is within a threshold of capturing any agent within the murmuration.
 \end{inparaenum} 
%Biologists tell us that

Let us now formalize definitions that will aid the modularization of the problem into manageable forms.
%

\begin{definition}[Neighbors of an Agent]
	We define the neighbors $\mc{N}_i(t)$ of agent $i$ at time $t$ as the set of all agents that lie within a predefined radius, $r_i$, of agent $i$ at time $t$. In every iteration of the game, we update an agent's neighbors as delineated in Algorithm \ref{alg:neighbors}.
\end{definition}
%
\begin{definition}
	We define a \textit{flock}, $\flock$, consisting of agents labeled $\{1, 2, \cdots, n\}$  as a collection of agents within a phase space $(\mc{X}, T)$ such that all agents within the flock interact with their nearest neighbors in a topological sense.
	\label{def:flock}
\end{definition}
%
\begin{remark}
	Every agent within a flock has similar dynamics to that of its neighbor(s). Furthermore, agents travel at the same linear speed, $v$; the angular headings, $w$, however, may be different between agents, seeing we are dealing with a many-bodied system. The state of an agent $i$ within a flock $j$ will be defined as $\state^{(i)_j}$ or $\state^i_j$. Each agent's continuous-time dynamics, $\dot{\state}^{(i)}(t)$, evolves as
	%
	\begin{align}
	%
	\begin{bmatrix}
		 \dot{\state}^{(i)}_1(t) \\ \dot{\state}^{(i)}_2 (t) \\ \dot{\state}^{(i)}_3 (t)
		\end{bmatrix} 
		= \begin{bmatrix}
			v(t) \cos \state_3^{(i)}(t) \\ v(t)\sin \state_3^{(i)}(t) \\ \langle w^{(i)}(t) \rangle_r
		\end{bmatrix},
		%
		%\\
		%
		%\text{ where } 
		 \langle w^{(i)}(t) \rangle_r = \dfrac{1}{1+n_i(t)}\left(w_i(t) + \sum_{j \in \mc{N}_i(t)}^{} w_j(t)\right) 
		\label{eq:DubinsJadbabaie}
	\end{align}
	%
	\text{ for agents } $i = \{1, 2, 3, ..., n\}$, where $t$ is the continuous-time index, $n_i(t)$ is the number of agent $i$'s neighbors at time $t$, $\mc{N}_i(t)$ denotes the sets of labels of  agent $i$'s neighbors at time $t$, and $\langle w^{(i)}(t) \rangle_r$ is the average orientation of agent $i$ w.r.t its neighbors at time $t$. Note that for a game where all agents share the same constant linear speed and heading, \eqref{eq:DubinsJadbabaie} reduces to the dynamics of a Dubins vehicle in absolute coordinates with $-\pi \le w^{(i)}(t) < \pi$. The averaging over the degrees of freedom of other agents in \eqref{eq:DubinsJadbabaie} is consistent with the \textit{mean field theory}, whereby the effect of all other agents on any one agent is an approximation of a single averaged influence.
\end{remark}

%Observe that the model of \eqref{eq:DubinsJadbabaie} is similar to the Dubins dynamics~\cite{Dubins1957} with the only difference being the update rule in the headings of the agents. This headings update rule is similar to the one used in statistical mechanics or  statistical physics (the physics of many interacting molecules)~\cite{Wilson1975}. We note here that it was recently adopted in control theory literature by Jadbabaie~\cite{JadbabaieCoord} in proving Viscek et al.'s self-driven particles simulations~\cite{Vicsek1995novel}.

\begin{definition}[Payoff of a Flock]
	To every flock $F_j$ (with a finite number of agents $N$) within a murmuration, $j = 1, 2, \cdots, m$ , we associate a payoff, $\bm{\Phi}$, that is the union of all respective agent's payoffs for expressing the outcome of a desired kinematic behavior. %with its neighbors. 
	\label{def:payoff}
\end{definition}
%
%The target set of each local group of agents within a flock, we leverage Definition 5.7 of \cite{BasarBook}.
%
%\begin{definition}[Flock Heading as an N-Person Game. Def. 5.7,~\cite{BasarBook}]
%	We consider the heading goal for a local flock $F_j$\footnote{The subscript $j$ of $F$ is used to identify a distinct flock of agents within a murmuration on a state space.} %within a murmuration of flocks $\flock$ 
%	as  an $N$-person differential game with a target set $\targetset_0^{j}$. The strategy $N$-tuple is said to be playable at $(\state_0, t_0)$ if it generates a trajectory $\traj(\cdot)$ such that $(\state(t), t) \in \targetset_0^{j}$ for finite $t$. Such a trajectory $\traj(\cdot)$ is said to be terminating.
%\end{definition}
%
%as an $N-tuple$ of  we now use \autoref{def:payoff} to show that the collective behavior of a flock of agents is the union of the respective payoffs for each agent within the flock.
%%
%\begin{theorem}
%	Something sm,ething
%\end{theorem}
%
%As mentioned in the introduction, we cannot solve the initial value problem in a classical way on $\ren \times [T, 0]$ in general. 
Viscosity solutions provide a particular means of finding a unique solution with a clear interpretation in terms of the generalized optimal control problem, even in the presence of stochastic perturbations. 
%
%Collective natural behavior in animals suggests that topological distance is used in maintaining group structure when density varies, so that the relationship between agents in a flock is not determined by the metric distance between nearest neighbors but rather the number of intermediate agents that separates two agent from one another.  Therefore, the neighbors of agent $i$ at time $t$ are those which are either within, or on a circle specified by a topological  distance, $r_c$. The topological metric is given  by the label of an agent and it quantifies the number of intermediate agents that separate two agents. 
%
%This is consistent with collective animal behaviors where individuals' bookkeeping on their neighbors' positions helps maintain the strength of an interaction when density varies or when they need to rorientation is its control input, given by the average of its own orientation and that of its neighbors. Instead of metric distance interaction rules that make agents very vulnerable to predation~\cite{Ballerini1232}, we resort to a topological interaction rule\footnote{With metric distance rules, we will have to formulate the breaking apart of value functions that encode a consensus heading problem in order to resolve the extrema of multiple payoffs; which is typically what we want to mitigate against during real-world autonomous tasks.}. 
%
Each agent within a flock interacts with a fixed number of neighbors, $n_c$, within a fixed topological range, $r_c$. This topological range %is given by the difference in the numerical label of individuals \cf \autoref{def:flock}, and 
is consistent with findings in collective swarm behaviors and it reinforces \textit{group cohesion}~\cite{Ballerini1232}. However, we are interested in \textit{robust group cohesion} in reachability analysis. Therefore, we let a pursuer, $\pursuer$, with a worst-possible disturbance attack the flock, and we take it that flocks of agents constitute an evading player, $\evader$. 
%
%
Returning to \eqref{eq:DubinsJadbabaie}, for a single flock, we now provide a sketch for the HJI formulation for a heading consensus problem. 

\subsection{Framework for Separated Payoffs}
%
We now make the following assumptions to enable our problem formulation.
%
Suppose that a murmuration's global heading is predetermined and each agent $i$ within each flock, $\flock_j,\, (j=1, \cdots, n)$ in the murmuration has a constant linear velocity, $v^i$. An agent's orientation is its control input, given by the average of its own orientation and that of its neighbors. Instead of metric distance interaction rules that make agents very vulnerable to predators~\cite{Ballerini1232}, we resort to a topological interaction rule\footnote{With metric distance rules, we will have to formulate the breaking apart of value functions that encode a consensus heading problem in order to resolve the extrema of multiple payoffs; which is typically what we want to mitigate against during real-world autonomous tasks.}. 


%\subsection{Nearest Neighbors Computation}
%
What constitutes an agent's neighbors are computed based on empirical findings and studies from the lateral vision of birds and fishes~\cite{Ballerini1232, JadbabaieCoord, Helbing20} that provide insights into their anisotropic kinematic density and structure. Importantly, starlings' lateral visual axes and their lack of a rear sector reinforces their lack of nearest neighbors in the front-rear direction. As such, this enables them to maintain a tight density and robust heading during formation and flight.
%
\begin{algorithm}[tb!]
	\caption{Nearest Neighbors For Agents in a Flock.
		\label{alg:neighbors}}
	\begin{algorithmic}[1]
		\State Given a set of agents $\bm{a} = \{a_1, a_2, \cdots, a_{n_a} \,| \,[a] = n_a\}$ 
		\Comment{$n_a$ agents in a flock  $\flock_k$.}
		\Function{UpdateNeighbor}{$n$}
		%\Comment{$N$: Total number of agents in flock.}
		%
		\For{$i$ in $1, \dots, n$}
		\Comment{Look to the right and update neighbors.}
		\label{alg:neighbors:line:lateral_vision_left}
		\For{$j$ in $i+1, \dots, n$}
		\State \textsc{Compare\_Neighbor($a[i]$, $a[j]$)}
		\EndFor
		%
		\For{$j$ in $i-1$ down to $0$}		
		\label{alg:neighbors:line:lateral_vision_right}
		\Comment{Look to the left and update neighbors.}
		\State \textsc{Compare\_Neighbor($a[i]$, $a[j]$)}
		\EndFor
		\EndFor
		%
		\For{each $a_i \in \flock_k, \, i=1, \cdots n_a$}
		\Comment{Recursively update agents' headings.}
		\State Update headings according to \eqref{eq:DubinsJadbabaie}.
		\EndFor 
		\EndFunction
	\end{algorithmic}
	%
	\hrule
	%
	\begin{algorithmic}[1]
		\Function{Compare\_Neighbor}{$a_1$, $a_2$}
		\Comment{$(a_1, a_2)$: distinct instances of AGENT.}
		\If{$|a_1.$label - $a_2.$label$|$ $< a_1.r^1_c$
			\label{alg:neighbors:line_neigh_rad}
			\Comment{$r^n_c$: agent $n$'s capture radius, $r_c$.}
			\State $a_1.$\textsf{\textsc{update\_neighbors}}($a_2$)}
		\EndIf
		\EndFunction
	\end{algorithmic}
	%
	\hrule
	%
	\begin{algorithmic}[1]
		\Procedure{Agent}{$a_i$, \textsf{Neighbors}=$\{\}$}  
		\Comment{Neighbors: Set of neighbors of this agent.}
		\State \Comment{Agent $a_i$ with attributes \textsf{label $\in \bb{N}$, avoid and capture radii, $r_a, r_c$.}}
		\Function{\textsf{\textsc{update\_neighbors}}}{\textsf{neigh}}	
		\If{\textsf{length(neigh)}$ > 1$}
		\Comment{Multiple neighbors.}
		\For{each \textsf{neighbor} of \textsf{neigh}}
		\State \textsc{\textsf{update\_neighbors}}(\textup{neighbor})
		\Comment{Recursive updates.}
		\EndFor 
		\EndIf
		%
		\State Add \textup{\textsf{neigh}} to \textsf{Neighbors}
		\EndFunction
		\EndProcedure
	\end{algorithmic}
\end{algorithm}
%
The algorithm for computing the nearest neighbors is given in Algorithm \autoref{alg:neighbors}. On lines \autoref{alg:neighbors:line:lateral_vision_left} and \autoref{alg:neighbors:line:lateral_vision_right} of Algorithm \autoref{alg:neighbors}, cohesion is reinforced by leveraging the observations above. While the neighbor updates for an agent involve an $O(n^2)$ algorithm in Algorithm \ref{alg:neighbors}, we are merely dealing with $6-7$ agents at a time in a local flock -- making the computational cost measly.

Each agent within a flock $\flock_j$ interacts with a fixed number of neighbors, $n_c$, within a fixed topological range, $r_c$\footnote{The topological range can be set as the distance between the labels of agents in a flock.}. This topological range %is given by the difference in the numerical label of individuals \cf \autoref{def:flock}, and 
is consistent with findings in collective swarm behaviors and it reinforces \textit{group cohesion}~\cite{Ballerini1232}. However, we are interested in \textit{robust group cohesion} in reachability analysis. Therefore, we let a pursuer, $\pursuer$, with a worst-possible disturbance attack the flock, and we take it that flocks of agents constitute an evading player, $\evader$. 

\subsection{Global Isotropy via Local Anisotropy}
%
%In this section, methods and results will ci=oincide. 
It has been observed that structural anisotropy is not merely an effect of a preferential velocity in animal flocking kinematics but rather an explicit effect of the anisotropic interaction character itself. By this theory, agents choose a mutual position on the state space in order to maximize the sensitivity to changes in heading and speed of neighbors as the neighbors' anisotropy is optimized and the scheme of avoiding collisions  is vision-based but not related to the eye's structure~\cite{Ballerini1232}.
 
Because of the robust group cohesion philosophy, we take it that at least one agent within a flock labeled $j$ is under attack and is in relative coordinates with a pursuer, $\pursuer^j$. By averaging the heading of individual agents' orientations with its neighbors\cf \eqref{eq:DubinsJadbabaie}, individual agents within a flock can achieve  fast  response to danger when a pursuer is nearby. In this specialized case,  capture does not necessarily occur, because the $\evader$ and $\pursuer$'s speeds and maximum turn radius are equal: if both players start the game with the same initial velocity and orientation, the relative equations of motion show that $\evader$ can mimic $\pursuer$'s strategy by forever keeping the starting radial separation. As such, the \textit{barrier} is closed and the \textit{game of kind} is to determine the surface~\cite{Merz1972}. However, owing to the high-dimensionality of the state space, we cannot resolve this barrier analytically, hence we resort to numerical approximation methods -- in particular, we leverage a parallel Lax-Friedrichs integration scheme~\cite{Crandall1984} which we implement in Cupy~\cite{CuPy} in order to provide a \textit{consistent} and \textit{monotone} solution to the Hamiltonians of these HJI equations. 
%

Therefore, for an agent $i$ within a flock with index $j$ in a murmuration, the equations of motion under attack from a predator $p$ (see \autoref{fig:robust_heading}) in relative coordinates is %and terminal conditions are given by
%
\begin{align}
\left[\begin{array}{c}
\dot{\state}_1^{(i)_j}(t) \\ \dot{\state}_2^{(i)_j} (t) \\ \dot{\state}_3^{(i)_j} (t)
\end{array}\right] = \begin{bmatrix}
-v_e^{(i)_j}(t) + v_p^{(j)} \cos \state_3^{(i)_j}(t) + \langle w_e^{(i)_j} \rangle_r \state_2^{(i)_j}(t)
%
\\
v_p^{(i)_j}(t)\sin \state_3^{(i)_j}(t) - \langle w_e^{(i)_j} \rangle_r \state_1^{(i)_j}(t)
\\ 
w_p^{(j)}(t) - \langle w_e^{(i)_j}(t) \rangle_r
\end{bmatrix} \, \text{for } i=1,\cdots, n_a
\label{eq:DubinsRelative}
\end{align}
%
where $n_a$ is the number of agents within a flock, $\left(\state_1^{(i)_j}(t), {\state}_2^{(i)_j} (t)\right) \in \bb{R}^2$, and  we have $\state_3^{(i)_j} (t) \in \left[-\pi, +\pi\right)$\footnote{We have multiplied the dynamics by $-1$ so that the extremal's resolution evolves backwards in time.}. Read ${\state}_1^{(i)_j}(t)$: the first component of the state of an agent $i$ at time $t$ which belongs to the flock $j$ in the murmuration at time $t$. In absolute coordinates, the equation of motion for \textit{free agents} is 
%
\begin{align}\left[\begin{array}{c}
		\dot{\state}_1^{(i)_j}(t) \\ \dot{\state}_2^{(i)_j} (t) \\ \dot{\state}_3^{(i)_j} (t)
	\end{array}\right] = \begin{bmatrix}
		v_e^{(i)_j}(t) \cos \state_3^{(i)_j}(t) 
		%
		\\
		v_e^{(i)_j}(t)\sin \state_3^{(i)_j}(t) 
		\\ 
		\langle w_e^{(i)_j}(t) \rangle_r
	\end{bmatrix}.
\end{align}
%
As mentioned in Section \ref{sec:notations}, the evading player at anytime has controls $\{\control^1, \control^2, \cdots \control^n\}$ for agents $i=1, \cdots, n$ completely  under its will. Solving for such complex backward reach-avoid tube is akin to splitting the state space into a number of parts separated by surfaces.  


\subsection{Flock Motion from Aggregated Value Functions}
We introduce the union operator \ie $\bigcup$ below as an aggregation symbol since the respective payoffs of each agent in a flock may be implicitly or explicitly constructed  on a grid\footnote{In resolving the zero-level sets of HJ value functions, it is typical to represent the payoff's surface as the isocontour of some function (usually a signed distance function).} -- when it is implicitly represented, say from a signed distance function, we shall aggregate the  payoff of agents 1 and 2 as
%
\begin{align}
	\bigcup\left(\Phi_1(\state, t), \Phi_2(\state, t)\right) = 	\min(\Phi_1(\state, t), \Phi_2(\state, t))
	\label{eq:sdf_union}
\end{align}
%
otherwise, other appropriate arithmetic or logical operation shall apply.

We assume that the \textit{value} of a flock heading control (differential game) exists.  And by an extension of Hamilton's principle of least action, the terminal motion of a flock coincide with the extremal of the payoff functional 
%
\begin{align}
	&\valuefunc(\state, t) = \inf_{\beta^{(1)} \in \mathcal{B}^{(1)}} \sup_{\bm{u^{(1)}} \in \mathcal{U^{(1)}}(t)} \int_{t_0}^{t_f} l^{(1)} (t, \state^{(1)}, \control^{(1)}, \beta^{(1)}[\control^{(1)}])dt +  g^{(1)}(\state(T)) \bigcup \cdots \nonumber
	%
	\\
	&\,  \inf_{\beta^{(n)} \in \mathcal{B}^{(n)}(t)} \sup_{\bm{u}^{(n)} \in \mathcal{U}^{(n)}(t)} \int_{t_0}^{t_f} l^{(n)} (t, \state^{(1)}, \control^{(1)}, \control^{(n)}, \beta^{(n)}[\control^{(n)}])dt + g^{(n)}(\state(T))
\end{align}
%
%\begin{subequations}
%\begin{align}\valuefunc_1(\state, t) \cup \cdots \cup \valuefunc_n
%&\frac{\partial \lowervalue_j}{\partial t} + \lowerham_j (t; \state, \bm{u}, \bm{v}, \lowervalue_{\state_j}) = 0, \,\, t\in \left[0, T\right]\, \state \in \ren  \\
%&\lowervalue_j(\state, T) = g_j(x(T)), \quad \state \in \reline^m , \quad j = 1, \cdots, n
%\label{eq:lower_visc_boundary_surfaces}
%\end{align}
%\label{eq:lower_visc_surfaces}
%\end{subequations}
%%
%
where $n$ is the total number of distinct flocks in a murmuration. The resolution of this equation  admits a viscosity solution~\cite{Evans1984} to following variational terminal HJI PDE \cite{Mitchell2005}
%
\begin{align}
	\bigcup_{i=1}^{n_f}\left[\bigcup_{i=1}^{n_a}\left(\dfrac{\partial \valuefunc_i}{\partial t}(\state, t) + \min \left[0, \hamfunc^{(i)}(\state^{(i)}, \valuefunc_x(\state, t))\right]\right)\right] = 0.
	\label{eq:value_aggregate}
\end{align}
%
with Hamiltonian, 
%
\begin{align}
	\hamfunc^{(i)} (t; \state^{(i)}, \bm{u}^{(i)}, \bm{v}^{(i)}, p^{(i)}) = \max_{u^{(i)} \in \mathcal{U}^{(i)}} \min_{v^{(i)} \in \mathcal{V}^{(i)}} \, \langle f^{(i)}(t; \state, \bm{u}^{(i)}, \bm{v}^{(i)}), p^{(i)}  \rangle. %, \quad i = 1, \cdots, n_a
	\label{eq:lower_visc_ham_surfaces}
\end{align}

In swarms' collective motion, when \eg a Peregrine Falcon attacks, immediate nearest agents change direction almost instantaneously. And because of the interdependence of the orientations of individual agents with respect to one another, all other agents respond based on the nearest neighbor formulation of \eqref{eq:DubinsJadbabaie} and Line \ref{alg:neighbors:line:lateral_vision_left} of Algorithm \ref{alg:neighbors}, every agent in a murmuration responds accordingly. Thus, we only simulate a single attack against a flock within the murmuration to realize robust cohesion.  

A pursuer can attack any flock within the murmuration from a distinct surface: a $\pursuer$ direction: this side of the surface reached after penetration in the $\pursuer-[\evader-]$ direction is the $\pursuer-[\evader]$ \textit{side}\cite{Isaacs1965}. We  attribute the term \textit{in the small} to determine the smooth parts of the singular surface solution when a pursuer attacks, and when they are stitched together into the total solution, we shall describe them as \textit{in the large}. There exists at least one value $\bar{\alpha}$ of $\alpha$ such that if $\alpha = \bar{\alpha}$, no vector in the $\beta$-vectogram\footnote{A $\beta-$vectogram is the resulting state space when a the strategy $\beta$ is applied in computing the optimal control law for an agent.} penetrates the surface in the $E$-direction. Similar arguments can be made for $\bar{\beta}$ which prevents penetration in the $P$-direction. We adopt ~\cite{Isaacs1965}'s terminology and call these surfaces semi-permeable surfaces (SPS).

Throughout the game, we assume that the roles of $\pursuer$  and $\evader$ do not change, so that when capture can occur, a necessary condition to be satisfied by the saddle-point controls of the players is the Hamiltonian, $\hamfunc^i(\state, p)$.  
%
\begin{theorem}
	For  a flock, $\flock_j$, the Hamiltonian is the total energy given by a summation of the exerted energy by each agent $i$ so that we can write the \textit{main equation} or total Hamiltonian of a murmuration as 
	%
	\begin{align}
		\hamfunc(\state, p) &= \max_{w_e^{(k)_j} \in [\underline{w}_e^j, \bar{w}_e^j]}  \min_{w_p^{(k)_j}  \in [\underline{w}_p^{j}, \bar{w}_p^j]} \bigcup_{j=1}^{n_f} \left[ H^{(k)_j}_a(\state, p) \bigcup \left( \bigcup_{i=1}^{n_a-1} H^{(i)_j}_f(\state, p) \right) \right] 
		\\
		%
		& = \bigcup_{j=1}^{n_f} \left( \bigcup_{i=1}^{n_a-1} 
			%
			\left[p_1^{(i)_j} \, v^{(i)_j} \cos \state_3 + p_2^{(i)_j} \, v^{(i)_j} \sin \state_3 + p_3^{(i)_j}\, \langle w_e^{(i)_j}\rangle_r\right] \right.\nonumber \\
			%
			& \qquad \left. \bigcup \left[
			%
			p_1^{(k)_j} \left(v^{(k)_j}  - v^{(k)_j} \cos \state_3^{(k)_j}\right) - p_2^{(k)_j} v^{(k)_j} \sin \state_3^{(k)_j} - \underline{w}_p^j |p_3^{(k)_j}|   \right. \right. \nonumber \\
			%
			& \qquad \qquad \left.  \left. 
			+ \bar{w}_e^j \bigg|p_2^{(k)_j} \state_1^{(k)_j} - p_1^{(k)_j}\state_2^{(k)_j} + p_3^{(k)_j}\bigg|
			\right] \right).
		\label{eq:HamiltonianOverall}
	\end{align}
	%
	where $\hamfunc^{(k)_j}_a(\state, p)$ is the  Hamiltonian of the individual under attack by a pursuing agent, $\pursuer$ and $H^{(i)_j}_f(\state, p)$ are the respective Hamiltonians of the free agents, $i=1, \cdots, n_f$, within an evading flock in a murmuration, and not under the direct influence of capture or attack by $\pursuer$; we denote by  $w_e^{(i)_j}$ the heading of an evader $i$ within a flock $j$ and $w_p^{(j)}$  the heading of a pursuer aimed at flock $j$; $\underline{w}_e^{(k)_j}$ is the orientation that corresponds to  the orientation of the agent with minimum turn radius among all the neighbors of agent $k$, inclusive of agent $k$ at time $t$; similarly, $\bar{w}_e^{(k)_j}$ is  the maximum orientation among all of the orientation of agent $k$'s neighbors. 
	\label{th:ham_sum}
\end{theorem}
%
\begin{corollary}
	For the special case where the linear speeds of the evading agents and pursuer are equal \ie $v_e^{(i)_j}(t) = v_p(t) = +1 m/s$, we have the Hamiltonian as
	%
	%\begin{align}
	%	\hamfunc(\state, p) &= \bigcup_{j=1}^{n_f} \bigcup_{i=1}^{n_a-1} p_1^{(i)} \left(1 - \cos \state_3^{(i)_j}\right) - p_2^{(i)_j} \sin \state_3^{(i)_j} - \underline{w}_p^j | p_3^{(i)_j}  |
	%	%
	%	\nonumber 	\\
	%	%
	%	& 
	%	+ \bar{w}_e^j | p_2^{(i)_j} \state_1^{(i)_j} - p_1^{(i)_j}\state_2^{(i)_j} + p_3^{(i)_j}| +
	%	%
	%	p_1^{(i)_j}v^{(i)_j} \cos \state_3 
	%	%
	%	\nonumber 	\\
	%	%
	%	&+ p_2^{(i)_j} v^{(i)_j} \sin \state_3 + p_3^{(i)_j} \langle w_e^{(i)_j}\rangle_r.
	%\end{align}
	%
	\begin{align}
		\hamfunc(\state, p) & = \bigcup_{j=1}^{n_f} \left( \bigcup_{i=1}^{n_a-1} 
		%
		\left[p_1^{(i)_j} \,  \cos \state_3 + p_2^{(i)_j} \,  \sin \state_3 + p_3^{(i)_j}\, \langle w_e^{(i)_j}\rangle_r\right] \right.\nonumber \\
		%
		& \qquad \left. \bigcup \left[
		%
		p_1^{(k)_j} \left(1 - \cos \state_3^{(k)_j}\right) - p_2^{(k)_j} \sin \state_3^{(k)_j} - \underline{w}_p^j |p_3^{(k)_j}|   \right. \right. \nonumber \\
		%
		& \qquad \left.  \left. 
		+ \bar{w}_e^j \bigg|p_2^{(k)_j} \state_1^{(k)_j} - p_1^{(k)_j}\state_2^{(k)_j} + p_3^{(k)_j}\bigg|
		\right] \right).
		\label{eq:HamiltonianCompletada}
	\end{align}
\end{corollary}
%
%\begin{proof}
%	The complete proof is provided in Appendix \ref{app:ham}.
%\end{proof}

We adopt the essentially non-oscillatory Lax-Friedrichs scheme of~\cite{OsherShuENO, Crandall1984Approx} in resolving \eqref{eq:HamiltonianCompletada}. Denote by $(x, y, z)$ a generic point in $\bb{R}^3$ so that given mesh sizes $\Delta x, \, \Delta y, \, \Delta z, \, \Delta t \, > 0$, letters $u,v,w$ will represent functions on the $x,y,z$ lattice $\Delta=\{(x_i,y_j, z_k): i, j, k \in \bb{Z}\}$. We define the numerical monotone flux, 	$\hat{\hamfunc}^{(i)_j}(\cdot)$, of $\hamfunc_j^{(i)}(\cdot)$ as 
%
\begin{align}
	\hat{\hamfunc}^{(i)_j}(u^+, u^-, v^+, v^-, w^+, w^-) = \hamfunc^{(i)_j}\left(\frac{u^+ +u^-}{2}, \frac{v^+ +v^-}{2}, \frac{w^+ +w^-}{2}\right) \nonumber
	%
	\\
	%
	- \dfrac{1}{2}\left[ \alpha_x^{(i)_j} \left(u^+ - u^-\right) + \alpha_y^{(i)_j}\left(v^+ - v^-\right) + \alpha_z^{(i)_j}\left(w^+ - w^-\right)\right]
\end{align}
%
where
%
\begin{align}
	\alpha_x^{(i)_j} = \max_{\substack{ a \le u \le b \\ c \le v \le d  \\ e \le w \le f}} |\hamfunc_{u}^{(i)_j}(\cdot)|, % = |1 - \cos \state_3^{(i)_j}|+ |\bar{w}_e^j \state_2^{(i)_j}|
	%
	%\\
	%
	\, \alpha_y^{(i)_j} = \max_{\substack{ a \le u \le b \\ c \le v \le d  \\ e \le w \le f}} |\hamfunc_{v}^{(i)_j}(\cdot)|, % = |\sin \state_3^{(i)_j}| + |\bar{w}_e^j \state_1^{(i)_j}|, \,  \\
	%
	\, \alpha_z^{(i)_j} = \max_{\substack{ a \le u \le b \\ c \le v \le d  \\ e \le w \le f}} |\hamfunc_{w}^{(i)_j}(\cdot)|. % = |\underline{w}_p^j + \bar{w}_e^j|
\end{align}
%
are dissipation coefficients, controlling the level of numerical viscosity in order to realize a stable solution that is physically realistic~\cite{Crandall1984Approx}. Here, the subscripts of $\hamfunc$ are the partial derivatives w.r.t the subscript variable, and the flux, $\hat{\hamfunc}(\cdot)$ is monotone for $a \le u^\pm \le b, c \le v^\pm \le d, e \le w^\pm \le f$. We adopt the total variation diminishing Runge-Kutta scheme of \cite{Osher1987} in efficiently calculating essentially non-oscillating upwinding finite difference gradients of $\hamfunc(\cdot)$.

\subsection{LargeBRAT as Chaining of Flockings' BRATs}
% 
\label{sucsec:murmur_funnels}

The theory we propose here is inspired by the algorithmic notions of robust, self-organizing emergent ``behaviors" such as those observed in   unactuated masses with passive mechanical guideways~\cite{SeqCompKoditschek} or murmurations. %Whereas the funneling idea of \cite{SeqCompKoditschek} provides a shifting control law that is only activated in each local partition of the state space when a system's state crosses the boundary towards each portion of the state space, ours is a chained control verification problem that is simultaneously executed across all partitions of the state space based on nearest neighbor rules between agents in order to realize aggressive control and safety verification over as large a state space as possible.

\begin{itemize}
	\item Chain backward in time, from a murmuration goal, to an attacked flocking's anisotropic heading direction~\cite{Lozano84} (Inspired from Nilsson 1980)
	%
	\item Mumrmuration BRAT verification strategy construed as a sequence of guarded motions~\cite{Grossman1975}
	%
	\item 
\end{itemize}

\todo{Under development.}